{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "z8o3HBAmspak"
      },
      "outputs": [],
      "source": [
        "#!wget https://dataworks.indianapolis.iu.edu/bitstream/handle/11243/41/data.zip\n",
        "#!unzip -q data.zip\n",
        "#!rm data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTwIpTTYsaIR",
        "outputId": "1d33d159-8db0-4c0a-c042-311c07b15310"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "import scipy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from functools import reduce\n",
        "\n",
        "torch.manual_seed(0)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Pc1BZG2saIW"
      },
      "source": [
        "# Dataset definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "n4jHfAYRsaIY"
      },
      "outputs": [],
      "source": [
        "class ImageDNATrainDataset():\n",
        "    def __init__(self, train=True):\n",
        "        splits_mat = scipy.io.loadmat(\"data/INSECTS/splits.mat\")\n",
        "        train_loc = splits_mat[\"train_loc\"]-1\n",
        "\n",
        "        TRAINING_SAMPLES_NUMBER = 12481\n",
        "        TRAINING_LABELS_NUMBER = 652\n",
        "\n",
        "        assert len(train_loc[0]) == TRAINING_SAMPLES_NUMBER\n",
        "\n",
        "        indeces = train_loc\n",
        "        # indeces.shape is (1, |indeces|), so we extract the whole list using [0]\n",
        "        indeces = indeces[0]\n",
        "\n",
        "        data_mat = scipy.io.loadmat(\"data/INSECTS/data.mat\")\n",
        "        self.embeddings_img = torch.from_numpy(\n",
        "            data_mat[\"embeddings_img\"][indeces]\n",
        "        ).float()\n",
        "        self.embeddings_dna = torch.from_numpy(\n",
        "            data_mat[\"embeddings_dna\"][indeces]\n",
        "        ).float()\n",
        "\n",
        "        # Remap seen species in [0, 651]\n",
        "        seen_species = data_mat[\"labels\"][train_loc][0]\n",
        "        seen_species_mapping = {label: i for i, label in enumerate(np.unique(seen_species))}\n",
        "\n",
        "        species_mapping = seen_species_mapping\n",
        "        assert len(species_mapping) == TRAINING_LABELS_NUMBER\n",
        "\n",
        "        species = data_mat[\"labels\"][indeces]\n",
        "        remapped_species = np.array([species_mapping[label.item()] for label in species])\n",
        "        self.remapped_species = torch.from_numpy(remapped_species).long()\n",
        "\n",
        "        assert len(torch.unique(self.remapped_species)) == TRAINING_LABELS_NUMBER\n",
        "\n",
        "        # data_mat['G'] returns a ndarray of type uint16, therefore we convert into int16 before invoking from_numpy\n",
        "        self.G = torch.from_numpy(data_mat[\"G\"].astype(np.int16)).long()\n",
        "        self.genera = torch.empty(species.shape).long()\n",
        "        for i in range(indeces.size):\n",
        "            self.genera[i][0] = self.G[species[i][0] - 1][0] - 1041\n",
        "\n",
        "        assert len(self.genera) == TRAINING_SAMPLES_NUMBER\n",
        "\n",
        "        self.species_names = data_mat[\"species\"][indeces]\n",
        "        self.ids = data_mat[\"ids\"][indeces]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.embeddings_dna)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        embedding_img = self.embeddings_img[idx]\n",
        "        embedding_dna = self.embeddings_dna[idx]\n",
        "        label = self.remapped_species[idx].item()\n",
        "        genera = self.genera[idx].item()\n",
        "\n",
        "        return embedding_img.view(1, -1), embedding_dna.view(1, -1), label, genera"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validation set\n",
        "- Number of samples: 6939.\n",
        "- Number of seen species of the training set in the validation set: 629.\n",
        "- Number of unseen species in the validation set: 97"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "GasJN0zyusZi"
      },
      "outputs": [],
      "source": [
        "class ImageDNAValidationDataset():\n",
        "    def __init__(self, train=True):\n",
        "        splits_mat = scipy.io.loadmat(\"data/INSECTS/splits.mat\")\n",
        "        train_loc = splits_mat[\"train_loc\"]-1\n",
        "        val_seen_loc = splits_mat[\"val_seen_loc\"]-1\n",
        "        val_unseen_loc = splits_mat[\"val_unseen_loc\"]-1\n",
        "\n",
        "        TRAINING_LABELS_NUMBER = 652\n",
        "        VALIDATION_SAMPLES_NUMBER = 6939\n",
        "        VALIDATION_SPECIES_NUMBER = 774\n",
        "        TRAINING_VALIDATION_SPECIES_NUMBER = 797\n",
        "        VALIDATION_SEEN_SPECIES_NUMBER = 629\n",
        "        VALIDATION_UNSEEN_SPECIES_GENERA_NUMBER = 97\n",
        "\n",
        "        indeces = np.concatenate((val_seen_loc, val_unseen_loc), axis=1)\n",
        "        # indeces.shape is (1, |indeces|), so we extract the whole list using [0]\n",
        "        indeces = indeces[0]\n",
        "        assert len(indeces) == VALIDATION_SAMPLES_NUMBER\n",
        "\n",
        "        data_mat = scipy.io.loadmat(\"data/INSECTS/data.mat\")\n",
        "        self.embeddings_img = torch.from_numpy(data_mat[\"embeddings_img\"][indeces]).float()\n",
        "        self.embeddings_dna = torch.from_numpy(data_mat[\"embeddings_dna\"][indeces]).float()\n",
        "\n",
        "        # Remap seen species in [0, 651]\n",
        "        seen_species = data_mat[\"labels\"][train_loc][0]\n",
        "        seen_species_mapping = {label: i for i, label in enumerate(np.unique(seen_species))}\n",
        "\n",
        "        # Remap unseen species during validation in [652, 796]\n",
        "        unseen_species = data_mat[\"labels\"][val_unseen_loc][0]\n",
        "        unseen_species_mapping = {label: i + TRAINING_LABELS_NUMBER for i, label in enumerate(np.unique(unseen_species))}\n",
        "\n",
        "        # Union of the two mappings, allows to fully remap all the labels\n",
        "        species_mapping = seen_species_mapping | unseen_species_mapping\n",
        "        assert len(species_mapping) == TRAINING_VALIDATION_SPECIES_NUMBER\n",
        "\n",
        "        species = data_mat[\"labels\"][indeces]\n",
        "        remapped_species = np.array([species_mapping[label.item()] for label in species])\n",
        "        self.remapped_species = torch.from_numpy(remapped_species).long()\n",
        "        assert len(torch.unique(self.remapped_species)) == VALIDATION_SPECIES_NUMBER\n",
        "\n",
        "        # data_mat['G'] returns a ndarray of type uint16, therefore we convert into int16 before invoking from_numpy\n",
        "        self.G = torch.from_numpy(data_mat[\"G\"].astype(np.int16)).long()\n",
        "        self.genera = torch.empty(species.shape).long()\n",
        "        for i in range(indeces.size):\n",
        "            self.genera[i][0] = self.G[species[i][0] - 1][0] - 1041\n",
        "\n",
        "        # Compute genera of unseen species in the validation set\n",
        "        unseen_species_genera = []\n",
        "        for i in val_unseen_loc[0]:\n",
        "            unseen_species_genera.append(data_mat[\"G\"][data_mat[\"labels\"][i][0] - 1][0] - 1041)\n",
        "        self.unseen_species_genera = np.array(unseen_species_genera)\n",
        "        assert len(np.unique(self.unseen_species_genera)) == VALIDATION_UNSEEN_SPECIES_GENERA_NUMBER\n",
        "\n",
        "        # Compute seen species number in the validation set\n",
        "        seen_species = []\n",
        "        for i in val_seen_loc[0]:\n",
        "            seen_species.append(species_mapping[data_mat[\"labels\"][i].item()])\n",
        "        self.seen_species = np.array(seen_species)\n",
        "        assert len(np.unique(self.seen_species)) == VALIDATION_SEEN_SPECIES_NUMBER\n",
        "\n",
        "        self.species_names = data_mat[\"species\"][indeces]\n",
        "        self.ids = data_mat[\"ids\"][indeces]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.embeddings_dna)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        embedding_img = self.embeddings_img[idx]\n",
        "        embedding_dna = self.embeddings_dna[idx]\n",
        "        label = self.remapped_species[idx].item()\n",
        "        genera = self.genera[idx].item()\n",
        "\n",
        "        return embedding_img.view(1, -1), embedding_dna.view(1, -1), label, genera"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test set\n",
        "- Number of samples: 13428.\n",
        "- Number of seen species of the training and validation set in the test set: 770.\n",
        "- Number of unseen species in the test set: 134"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "MKdIHeWZusZj"
      },
      "outputs": [],
      "source": [
        "class ImageDNATestDataset(Dataset):\n",
        "    def __init__(self, train=True):\n",
        "        splits_mat = scipy.io.loadmat(\"data/INSECTS/splits.mat\")\n",
        "        train_loc = splits_mat[\"train_loc\"]-1\n",
        "        trainval_loc = splits_mat[\"trainval_loc\"]-1\n",
        "        test_seen_loc = splits_mat[\"test_seen_loc\"]-1\n",
        "        test_unseen_loc = splits_mat[\"test_unseen_loc\"]-1\n",
        "        val_seen_loc = splits_mat[\"val_seen_loc\"]-1\n",
        "        val_unseen_loc = splits_mat[\"val_unseen_loc\"]-1\n",
        "\n",
        "        TRAINING_SPECIES_NUMBER = 652\n",
        "        TRAINING_VALIDATION_SPECIES = 797\n",
        "        NUMBER_OF_SPECIES = 1040\n",
        "        TEST_SEEN_SPECIES_NUMBER = 770\n",
        "        TEST_UNSEEN_SPECIES_GENERA_NUMBER = 134\n",
        "\n",
        "        indeces = np.concatenate((test_seen_loc, test_unseen_loc), axis=1)\n",
        "        # indeces.shape is (1, |indeces|), so we extract the whole list using [0]\n",
        "        indeces = indeces[0]\n",
        "\n",
        "        data_mat = scipy.io.loadmat(\"data/INSECTS/data.mat\")\n",
        "        self.embeddings_img = torch.from_numpy(data_mat[\"embeddings_img\"][indeces]).float()\n",
        "        self.embeddings_dna = torch.from_numpy(data_mat[\"embeddings_dna\"][indeces]).float()\n",
        "\n",
        "        # Remap seen species in [0, 651]\n",
        "        seen_species = data_mat[\"labels\"][train_loc][0]\n",
        "        seen_species_mapping = {label: i for i, label in enumerate(np.unique(seen_species))}\n",
        "\n",
        "        # Remap unseen species during validation in [652, 796]\n",
        "        unseen_species_validation = data_mat[\"labels\"][val_unseen_loc][0]\n",
        "        unseen_species_validation_mapping = {label: i + TRAINING_SPECIES_NUMBER for i, label in enumerate(np.unique(unseen_species_validation))}\n",
        "\n",
        "        # Remap unseen species during test in [797, 1039]\n",
        "        unseen_species_test = data_mat[\"labels\"][test_unseen_loc][0]\n",
        "        unseen_species_test_mapping = {label: i + TRAINING_VALIDATION_SPECIES for i, label in enumerate(np.unique(unseen_species_test))}\n",
        "\n",
        "        assert reduce(np.intersect1d, (seen_species, unseen_species_validation, unseen_species_test)).size == 0\n",
        "\n",
        "        # Union of the two mappings, allows to full remap all the labels\n",
        "        labels_mapping = seen_species_mapping | unseen_species_validation_mapping | unseen_species_test_mapping\n",
        "        assert len(labels_mapping) == NUMBER_OF_SPECIES\n",
        "\n",
        "        species = data_mat[\"labels\"][indeces]\n",
        "        remapped_labels = np.array([labels_mapping[label.item()] for label in species])\n",
        "        self.remapped_labels = torch.from_numpy(remapped_labels).long()\n",
        "\n",
        "        # data_mat['G'] returns a ndarray of type uint16, therefore we convert into int16 before invoking from_numpy\n",
        "        self.G = torch.from_numpy(data_mat[\"G\"].astype(np.int16)).long()\n",
        "        self.genera = torch.empty(species.shape).long()\n",
        "        for i in range(indeces.size):\n",
        "            self.genera[i][0] = self.G[species[i][0] - 1][0] - 1041\n",
        "\n",
        "        # Compute genera of unseen species\n",
        "        unseen_species_genera = []\n",
        "        for i in test_unseen_loc[0]:\n",
        "            unseen_species_genera.append(data_mat[\"G\"][data_mat[\"labels\"][i][0] - 1][0] - 1041)\n",
        "\n",
        "        self.unseen_species_genera = np.array(unseen_species_genera)\n",
        "        assert len(np.unique(self.unseen_species_genera)) == TEST_UNSEEN_SPECIES_GENERA_NUMBER\n",
        "\n",
        "        # Compute seen species\n",
        "        seen_species = []\n",
        "        for i in test_seen_loc[0]:\n",
        "            seen_species.append(labels_mapping[data_mat[\"labels\"][i].item()])\n",
        "        self.seen_species = np.array(seen_species)\n",
        "        assert len(np.unique(self.seen_species)) == TEST_SEEN_SPECIES_NUMBER\n",
        "\n",
        "        self.species_name = data_mat[\"species\"][indeces]\n",
        "        self.ids = data_mat[\"ids\"][indeces]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.embeddings_dna)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        embedding_img = self.embeddings_img[idx]\n",
        "        embedding_dna = self.embeddings_dna[idx]\n",
        "        label = self.remapped_labels[idx].item()\n",
        "        genera = self.genera[idx].item()\n",
        "\n",
        "        return embedding_img.view(1, -1), embedding_dna.view(1, -1), label, genera"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "PWLG3L3eusZl"
      },
      "outputs": [],
      "source": [
        "class ImageDNATrainValidationDataset(Dataset):\n",
        "    def __init__(self, train=True):\n",
        "        splits_mat = scipy.io.loadmat(\"data/INSECTS/splits.mat\")\n",
        "        train_loc = splits_mat[\"train_loc\"]-1\n",
        "        trainval_loc = splits_mat[\"trainval_loc\"]-1\n",
        "        test_seen_loc = splits_mat[\"test_seen_loc\"]-1\n",
        "        test_unseen_loc = splits_mat[\"test_unseen_loc\"]-1\n",
        "        val_seen_loc = splits_mat[\"val_seen_loc\"]-1\n",
        "        val_unseen_loc = splits_mat[\"val_unseen_loc\"]-1\n",
        "\n",
        "        TRAINING_SPECIES_NUMBER = 652\n",
        "        TRAINING_VALIDATION_SPECIES = 797\n",
        "        NUMBER_OF_SPECIES = 1040\n",
        "\n",
        "        indeces = trainval_loc\n",
        "        # indeces.shape is (1, |indeces|), so we extract the whole list using [0]\n",
        "        indeces = indeces[0]\n",
        "\n",
        "        data_mat = scipy.io.loadmat(\"data/INSECTS/data.mat\")\n",
        "        self.embeddings_img = torch.from_numpy(data_mat[\"embeddings_img\"][indeces]).float()\n",
        "        self.embeddings_dna = torch.from_numpy(data_mat[\"embeddings_dna\"][indeces]).float()\n",
        "\n",
        "        # Remap seen species in [0, 651]\n",
        "        seen_species = data_mat[\"labels\"][train_loc][0]\n",
        "        seen_species_mapping = {label: i for i, label in enumerate(np.unique(seen_species))}\n",
        "\n",
        "        # Remap unseen species during validation in [652, 796]\n",
        "        unseen_species_validation = data_mat[\"labels\"][val_unseen_loc][0]\n",
        "        unseen_species_validation_mapping = {label: i + TRAINING_SPECIES_NUMBER for i, label in enumerate(np.unique(unseen_species_validation))}\n",
        "\n",
        "        # Remap unseen species during test in [797, 1039]\n",
        "        unseen_species_test = data_mat[\"labels\"][test_unseen_loc][0]\n",
        "        unseen_species_test_mapping = {label: i + TRAINING_VALIDATION_SPECIES for i, label in enumerate(np.unique(unseen_species_test))}\n",
        "\n",
        "        assert reduce(np.intersect1d, (seen_species, unseen_species_validation, unseen_species_test)).size == 0\n",
        "\n",
        "        # Union of the two mappings, allows to full remap all the labels\n",
        "        labels_mapping = seen_species_mapping | unseen_species_validation_mapping | unseen_species_test_mapping\n",
        "        assert len(labels_mapping) == NUMBER_OF_SPECIES\n",
        "\n",
        "        species = data_mat[\"labels\"][indeces]  # Consider only train\n",
        "        remapped_labels = np.array([labels_mapping[label.item()] for label in species])\n",
        "        self.remapped_labels = torch.from_numpy(remapped_labels).long()\n",
        "\n",
        "        assert len(torch.unique(self.remapped_labels)) == TRAINING_VALIDATION_SPECIES\n",
        "\n",
        "        # data_mat['G'] returns a ndarray of type uint16, therefore we convert into int16 before invoking from_numpy\n",
        "        self.G = torch.from_numpy(data_mat[\"G\"].astype(np.int16)).long()\n",
        "        self.genera = torch.empty(species.shape).long()\n",
        "        for i in range(indeces.size):\n",
        "            self.genera[i][0] = self.G[species[i][0] - 1][0] - 1041\n",
        "\n",
        "        self.species = data_mat[\"species\"][indeces]\n",
        "        self.ids = data_mat[\"ids\"][indeces]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.embeddings_dna)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        embedding_img = self.embeddings_img[idx]\n",
        "        embedding_dna = self.embeddings_dna[idx]\n",
        "        label = self.remapped_labels[idx].item()\n",
        "        genera = self.genera[idx].item()\n",
        "\n",
        "        return embedding_img.view(1, -1), embedding_dna.view(1, -1), label, genera\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg3l8IA0saIb"
      },
      "source": [
        "# Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "fp_osQc7usZm"
      },
      "outputs": [],
      "source": [
        "class AttentionNet(nn.Module):\n",
        "        def __init__(self, num_seen_species, num_genera):\n",
        "                super(AttentionNet, self).__init__()\n",
        "\n",
        "                self.img_fc1 = nn.Linear(2048, 1024)\n",
        "                self.img_fc2 = nn.Linear(1024, 512)\n",
        "\n",
        "                \n",
        "                self.dna_fc1 = nn.Linear(500, 512)\n",
        "\n",
        "                self.img_dna_encoder_1 = ImageDNAEncoder(512, 2 * 512, 4)\n",
        "\n",
        "                self.fc_species_1 = nn.Linear(1024, 1024)\n",
        "                self.fc_species_2 = nn.Linear(1024, num_seen_species)\n",
        "\n",
        "                self.fc_genera_1 = nn.Linear(1024, 512)\n",
        "                self.fc_genera_2 = nn.Linear(512, num_genera)\n",
        "\n",
        "                self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "\n",
        "        def forward(self, x_img, x_dna):\n",
        "                x_img = self.img_fc2(F.leaky_relu(self.img_fc1(x_img)))\n",
        "                x_dna = self.dna_fc1(x_dna)\n",
        "\n",
        "                x_img, x_dna = self.img_dna_encoder_1(x_img, x_dna)\n",
        "\n",
        "                x = torch.cat((x_img, x_dna), axis=2)\n",
        "                x = torch.squeeze(x, dim=1)\n",
        "\n",
        "                x_species = x.clone()\n",
        "                x_genera = x.clone()\n",
        "\n",
        "                x_species = self.dropout(F.leaky_relu(self.fc_species_1(x_species)))\n",
        "                x_species = self.fc_species_2(x_species)\n",
        "\n",
        "                x_genera = self.dropout(F.leaky_relu(self.fc_genera_1(x_genera)))\n",
        "                x_genera = self.fc_genera_2(x_genera)\n",
        "\n",
        "                return x_species, x_genera\n",
        "\n",
        "class ImageDNAEncoder(nn.Module):\n",
        "        def __init__(self, embed_dim, linear_dim, num_heads):\n",
        "                super(ImageDNAEncoder, self).__init__()\n",
        "                self.multi_head_img_1 = nn.MultiheadAttention(embed_dim, num_heads)\n",
        "                self.multi_head_dna_1 = nn.MultiheadAttention(embed_dim, num_heads)\n",
        "\n",
        "                self.norm_img_1 = nn.LayerNorm(embed_dim)\n",
        "                self.norm_dna_1 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "                self.linear_img_1 = nn.Linear(embed_dim, linear_dim)\n",
        "                self.dropout_img = nn.Dropout(0.5)\n",
        "                self.linear_img_2 = nn.Linear(linear_dim, embed_dim)\n",
        "\n",
        "                self.linear_dna_1 = nn.Linear(embed_dim, linear_dim)\n",
        "                self.dropout_dna = nn.Dropout(0.5)\n",
        "                self.linear_dna_2 = nn.Linear(linear_dim, embed_dim)\n",
        "\n",
        "\n",
        "        def forward(self, x_img, x_dna):\n",
        "                identity = x_img\n",
        "                x_img, _ = self.multi_head_img_1(x_img, x_dna, x_dna)\n",
        "                x_img = self.norm_img_1(x_img + identity)\n",
        "                x_img = self.feed_forward_img(x_img)\n",
        "\n",
        "                identity = x_dna\n",
        "                x_dna, _ = self.multi_head_dna_1(x_dna, x_img, x_img)\n",
        "                x_dna = self.norm_dna_1(x_dna + identity)\n",
        "                x_dna = self.feed_forward_dna(x_dna)\n",
        "\n",
        "                return x_img, x_dna\n",
        "\n",
        "        def feed_forward_img(self, x):\n",
        "                return self.linear_img_2(self.dropout_img(F.relu(self.linear_img_1(x))))\n",
        "\n",
        "        def feed_forward_dna(self, x):\n",
        "                return self.linear_dna_2(self.dropout_dna(F.relu(self.linear_dna_1(x))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEj9iqWHsaId"
      },
      "source": [
        "# Creating datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Of4Mq0hKsaId"
      },
      "outputs": [],
      "source": [
        "training_set = ImageDNATrainDataset()\n",
        "validation_set = ImageDNAValidationDataset()\n",
        "test_set = ImageDNATestDataset()\n",
        "training_validation_set = ImageDNATrainValidationDataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c93Uli0msaIe"
      },
      "source": [
        "Defining methods for training, validating and testing the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "ti1M7rRAusZp"
      },
      "outputs": [],
      "source": [
        "def validate(model, threshold, batch_size):\n",
        "\n",
        "    validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=False)\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        correct_predictions_per_labels = defaultdict(int)\n",
        "        total_samples_per_labels = defaultdict(int)\n",
        "        correct_predictions_per_genera = defaultdict(int)\n",
        "        total_samples_per_genera = defaultdict(int)\n",
        "\n",
        "        for data in validation_loader:\n",
        "            inputs_img, inputs_dna, species, genera = data\n",
        "            inputs_img, inputs_dna, species, genera = inputs_img.to(device), inputs_dna.to(device), species.to(device), genera.to(device)\n",
        "\n",
        "            labels_outputs, genera_outputs = model(inputs_img, inputs_dna)\n",
        "\n",
        "            labels_outputs = nn.Softmax(dim=1)(labels_outputs)\n",
        "            genera_outputs = nn.Softmax(dim=1)(genera_outputs)\n",
        "\n",
        "            predicted_labels_values, predicted_labels = torch.topk(labels_outputs.data, k=2, dim=1)\n",
        "            _, predicted_genera = torch.max(genera_outputs.data, 1)\n",
        "\n",
        "            differences = predicted_labels_values[:, 0] - predicted_labels_values[:, 1]\n",
        "            genera_mask = differences <= threshold\n",
        "            labels_mask = ~genera_mask\n",
        "\n",
        "            # Update relative frequencies\n",
        "            for idx in range(len(genera)):\n",
        "                total_samples_per_labels[species[idx].item()] += 1\n",
        "\n",
        "                if labels_mask[idx] and predicted_labels[idx, 0] == species[idx]:\n",
        "                    correct_predictions_per_labels[species[idx].item()] += 1\n",
        "\n",
        "                # if the sample is of one undescribed species\n",
        "                if species[idx].item() not in np.unique(validation_set.seen_species):\n",
        "                    assert genera[idx].item() in np.unique(validation_set.unseen_species_genera)\n",
        "                    total_samples_per_genera[genera[idx].item()] += 1\n",
        "\n",
        "                    if genera_mask[idx] and predicted_genera[idx] == genera[idx]:\n",
        "                        correct_predictions_per_genera[genera[idx].item()] += 1\n",
        "\n",
        "        accuracy_per_label = {label: (correct_predictions_per_labels[label] / total_samples_per_labels[label]) if total_samples_per_labels[label] > 0 else 0 for label in total_samples_per_labels}\n",
        "        accuracy_per_genera = {genera: (correct_predictions_per_genera[genera] / total_samples_per_genera[genera]) if total_samples_per_genera[genera] > 0 else 0 for genera in total_samples_per_genera}\n",
        "\n",
        "        test_described_species_accuracy = 0\n",
        "        for label in np.unique(validation_set.seen_species):\n",
        "            test_described_species_accuracy += accuracy_per_label[label]\n",
        "\n",
        "        test_undescribed_species_accuracy = 0\n",
        "        for genera in np.unique(validation_set.unseen_species_genera):\n",
        "            test_undescribed_species_accuracy += accuracy_per_genera[genera]\n",
        "\n",
        "        normalized_test_described_species_accuracy = test_described_species_accuracy / 629\n",
        "        normalized_test_undescribed_species_accuracy = test_undescribed_species_accuracy / 97\n",
        "\n",
        "        return normalized_test_described_species_accuracy, normalized_test_undescribed_species_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "87_ldlBDusZp"
      },
      "outputs": [],
      "source": [
        "def test(model, threshold, batch_size):\n",
        "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        correct_predictions_per_labels = defaultdict(int)\n",
        "        total_samples_per_labels = defaultdict(int)\n",
        "        correct_predictions_per_genera = defaultdict(int)\n",
        "        total_samples_per_genera = defaultdict(int)\n",
        "\n",
        "        for data in test_loader:\n",
        "            inputs_img, inputs_dna, species, genera = data\n",
        "            inputs_img, inputs_dna, species, genera = inputs_img.to(device), inputs_dna.to(device), species.to(device), genera.to(device)\n",
        "\n",
        "            labels_outputs, genera_outputs = model(inputs_img, inputs_dna)\n",
        "\n",
        "            labels_outputs = nn.Softmax(dim=1)(labels_outputs)\n",
        "            genera_outputs = nn.Softmax(dim=1)(genera_outputs)\n",
        "\n",
        "            predicted_labels_values, predicted_labels = torch.topk(labels_outputs.data, k=2, dim=1)\n",
        "            _, predicted_genera = torch.max(genera_outputs.data, 1)\n",
        "\n",
        "            differences = predicted_labels_values[:, 0] - predicted_labels_values[:, 1]\n",
        "            genera_mask = differences <= threshold\n",
        "            labels_mask = ~genera_mask\n",
        "\n",
        "            # Update relative frequencies\n",
        "            for idx in range(len(genera)):\n",
        "                total_samples_per_labels[species[idx].item()] += 1\n",
        "\n",
        "                if labels_mask[idx] and predicted_labels[idx, 0] == species[idx]:\n",
        "                    correct_predictions_per_labels[species[idx].item()] += 1\n",
        "\n",
        "                # if the sample is of one undescribed species\n",
        "                if species[idx].item() not in np.unique(test_set.seen_species):\n",
        "                    assert genera[idx].item() in np.unique(test_set.unseen_species_genera)\n",
        "                    total_samples_per_genera[genera[idx].item()] += 1\n",
        "\n",
        "                    if genera_mask[idx] and predicted_genera[idx] == genera[idx]:\n",
        "                        correct_predictions_per_genera[genera[idx].item()] += 1\n",
        "\n",
        "        accuracy_per_label = {label: (correct_predictions_per_labels[label] / total_samples_per_labels[label]) if total_samples_per_labels[label] > 0 else 0 for label in total_samples_per_labels}\n",
        "        accuracy_per_genera = {genera: (correct_predictions_per_genera[genera] / total_samples_per_genera[genera]) if total_samples_per_genera[genera] > 0 else 0 for genera in total_samples_per_genera}\n",
        "\n",
        "        test_described_species_accuracy = 0\n",
        "        for label in np.unique(test_set.seen_species):\n",
        "            test_described_species_accuracy += accuracy_per_label[label]\n",
        "\n",
        "        test_undescribed_species_accuracy = 0\n",
        "        for genera in np.unique(test_set.unseen_species_genera):\n",
        "            test_undescribed_species_accuracy += accuracy_per_genera[genera]\n",
        "\n",
        "        normalized_test_described_species_accuracy = test_described_species_accuracy / 770\n",
        "        normalized_test_undescribed_species_accuracy = test_undescribed_species_accuracy / 134\n",
        "\n",
        "        return normalized_test_described_species_accuracy, normalized_test_undescribed_species_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def train(model, lr, momentum, max_epochs, batch_size, train_val=False, print_losses=False, print_step=200):\n",
        "    model.train()\n",
        "    criterion_species = torch.nn.CrossEntropyLoss()\n",
        "    criterion_genera = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "    \n",
        "    if train_val:\n",
        "        loader = torch.utils.data.DataLoader(training_validation_set, batch_size=batch_size, shuffle=True)\n",
        "    else:\n",
        "        loader = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
        "    \n",
        "    # Variables for early stopping\n",
        "    validation_genera_loss = 0\n",
        "    best_validation_genera_loss = np.inf\n",
        "    \n",
        "    for epoch in range(max_epochs):\n",
        "        model.train()\n",
        "        running_labels_loss = 0.0\n",
        "        running_genera_loss = 0.0\n",
        "\n",
        "        for i, data in enumerate(loader, 0):\n",
        "            inputs_img, inputs_dna, species, genera = data\n",
        "            inputs_img, inputs_dna, species, genera = inputs_img.to(device), inputs_dna.to(device), species.to(device), genera.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            species_outputs, genera_outputs = model(inputs_img, inputs_dna)\n",
        "            labels_loss = criterion_species(species_outputs, species)\n",
        "            genera_loss = criterion_genera(genera_outputs, genera)\n",
        "            total_loss = labels_loss + genera_loss\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print losses\n",
        "            if print_losses:\n",
        "                running_labels_loss += labels_loss.item()\n",
        "                running_genera_loss += genera_loss.item()\n",
        "                if i % print_step == print_step - 1:\n",
        "                    print(f\"[{epoch + 1}, {i + 1:5d}] Species loss: {running_labels_loss / print_step:.3f}; Genera loss: {running_genera_loss / print_step:.3f}\")\n",
        "                    running_labels_loss = 0.0\n",
        "                    running_genera_loss = 0.0\n",
        "\n",
        "        if (not train_val):\n",
        "            # Early stopping\n",
        "            patience = 20\n",
        "            validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=True)\n",
        "            model.eval()\n",
        "            validation_genera_loss = 0.0\n",
        "            with torch.no_grad():\n",
        "                for data in validation_loader:\n",
        "                    inputs_img, inputs_dna, species, genera = data\n",
        "                    inputs_img, inputs_dna, _, genera = inputs_img.to(device), inputs_dna.to(device), species.to(device), genera.to(device)\n",
        "                    _, genera_outputs = model(inputs_img, inputs_dna)\n",
        "                    validation_genera_loss += criterion_genera(genera_outputs, genera).item() * inputs_img.size(0)\n",
        "\n",
        "            validation_genera_loss = validation_genera_loss / len(validation_loader.dataset)\n",
        "            print(f'Epoch {epoch+1}/{max_epochs} Validation genera Loss: {validation_genera_loss:.3f}')\n",
        "\n",
        "            # Check if validation loss improved\n",
        "            if validation_genera_loss < best_validation_genera_loss:\n",
        "                best_validation_genera_loss = validation_genera_loss\n",
        "                patience_counter = 0\n",
        "                torch.save(model.state_dict(), 'best_model_early_stopping.pth')\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            # Early stopping\n",
        "            if patience_counter >= patience:\n",
        "                print(f'Early stopping at epoch {epoch+1}')\n",
        "                break\n",
        "\n",
        "    if not train_val:\n",
        "        model.load_state_dict(torch.load('best_model_early_stopping.pth'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model selection\n",
        "We tune the following hyperparameters through model selection:\n",
        "- Learning rate\n",
        "- Threshold\n",
        "- Embedding dimensions and number of heads of the inception block\n",
        "We select the values that maximizes the sum of seen species accuracy and unseen genera accuracy on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zItvqJfusZq",
        "outputId": "86c6e8bb-9703-41ff-e6a1-f04172f9451a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,   200] Species loss: 5.179; Genera loss: 4.228\n",
            "[1,   400] Species loss: 3.508; Genera loss: 2.573\n",
            "[1,   600] Species loss: 2.625; Genera loss: 1.956\n",
            "Epoch 1/100 Validation genera Loss: 2.268\n",
            "[2,   200] Species loss: 1.473; Genera loss: 1.142\n",
            "[2,   400] Species loss: 1.147; Genera loss: 0.896\n",
            "[2,   600] Species loss: 0.928; Genera loss: 0.759\n",
            "Epoch 2/100 Validation genera Loss: 1.852\n",
            "[3,   200] Species loss: 0.527; Genera loss: 0.451\n",
            "[3,   400] Species loss: 0.404; Genera loss: 0.449\n",
            "[3,   600] Species loss: 0.321; Genera loss: 0.398\n",
            "Epoch 3/100 Validation genera Loss: 2.348\n",
            "[4,   200] Species loss: 0.262; Genera loss: 0.339\n",
            "[4,   400] Species loss: 0.287; Genera loss: 0.361\n",
            "[4,   600] Species loss: 0.230; Genera loss: 0.316\n",
            "Epoch 4/100 Validation genera Loss: 2.388\n",
            "[5,   200] Species loss: 0.235; Genera loss: 0.277\n",
            "[5,   400] Species loss: 0.185; Genera loss: 0.250\n",
            "[5,   600] Species loss: 0.160; Genera loss: 0.255\n",
            "Epoch 5/100 Validation genera Loss: 2.496\n",
            "[6,   200] Species loss: 0.242; Genera loss: 0.361\n",
            "[6,   400] Species loss: 0.244; Genera loss: 0.431\n",
            "[6,   600] Species loss: 0.284; Genera loss: 0.495\n",
            "Epoch 6/100 Validation genera Loss: 2.592\n",
            "[7,   200] Species loss: 0.322; Genera loss: 0.320\n",
            "[7,   400] Species loss: 0.272; Genera loss: 0.474\n",
            "[7,   600] Species loss: 0.242; Genera loss: 0.445\n",
            "Epoch 7/100 Validation genera Loss: 2.657\n",
            "[8,   200] Species loss: 0.301; Genera loss: 0.548\n",
            "[8,   400] Species loss: 0.314; Genera loss: 0.533\n",
            "[8,   600] Species loss: 0.330; Genera loss: 0.611\n",
            "Epoch 8/100 Validation genera Loss: 3.443\n",
            "[9,   200] Species loss: 0.383; Genera loss: 0.567\n",
            "[9,   400] Species loss: 0.579; Genera loss: 0.731\n",
            "[9,   600] Species loss: 0.350; Genera loss: 0.648\n",
            "Epoch 9/100 Validation genera Loss: 2.764\n",
            "[10,   200] Species loss: 0.477; Genera loss: 0.846\n",
            "[10,   400] Species loss: 0.463; Genera loss: 0.695\n",
            "[10,   600] Species loss: 0.469; Genera loss: 0.752\n",
            "Epoch 10/100 Validation genera Loss: 5.542\n",
            "[11,   200] Species loss: 4.789; Genera loss: 2.754\n",
            "[11,   400] Species loss: 1.763; Genera loss: 1.527\n",
            "[11,   600] Species loss: 1.024; Genera loss: 0.972\n",
            "Epoch 11/100 Validation genera Loss: 3.742\n",
            "[12,   200] Species loss: 0.564; Genera loss: 0.633\n",
            "[12,   400] Species loss: 0.458; Genera loss: 0.574\n",
            "[12,   600] Species loss: 0.433; Genera loss: 0.466\n",
            "Epoch 12/100 Validation genera Loss: 2.470\n",
            "[13,   200] Species loss: 0.314; Genera loss: 0.403\n",
            "[13,   400] Species loss: 0.190; Genera loss: 0.344\n",
            "[13,   600] Species loss: 0.216; Genera loss: 0.236\n",
            "Epoch 13/100 Validation genera Loss: 3.354\n",
            "[14,   200] Species loss: 0.168; Genera loss: 0.222\n",
            "[14,   400] Species loss: 0.218; Genera loss: 0.226\n",
            "[14,   600] Species loss: 0.157; Genera loss: 0.188\n",
            "Epoch 14/100 Validation genera Loss: 2.875\n",
            "[15,   200] Species loss: 0.135; Genera loss: 0.202\n",
            "[15,   400] Species loss: 0.142; Genera loss: 0.168\n",
            "[15,   600] Species loss: 0.129; Genera loss: 0.132\n",
            "Epoch 15/100 Validation genera Loss: 2.960\n",
            "[16,   200] Species loss: 0.130; Genera loss: 0.186\n",
            "[16,   400] Species loss: 0.102; Genera loss: 0.208\n",
            "[16,   600] Species loss: 0.104; Genera loss: 0.157\n",
            "Epoch 16/100 Validation genera Loss: 3.494\n",
            "[17,   200] Species loss: 0.075; Genera loss: 0.199\n",
            "[17,   400] Species loss: 0.102; Genera loss: 0.154\n",
            "[17,   600] Species loss: 0.080; Genera loss: 0.097\n",
            "Epoch 17/100 Validation genera Loss: 2.590\n",
            "[18,   200] Species loss: 0.085; Genera loss: 0.174\n",
            "[18,   400] Species loss: 0.091; Genera loss: 0.146\n",
            "[18,   600] Species loss: 0.053; Genera loss: 0.121\n",
            "Epoch 18/100 Validation genera Loss: 2.880\n",
            "[19,   200] Species loss: 0.064; Genera loss: 0.089\n",
            "[19,   400] Species loss: 0.061; Genera loss: 0.093\n",
            "[19,   600] Species loss: 0.083; Genera loss: 0.108\n",
            "Epoch 19/100 Validation genera Loss: 3.049\n",
            "[20,   200] Species loss: 0.080; Genera loss: 0.081\n",
            "[20,   400] Species loss: 0.039; Genera loss: 0.086\n",
            "[20,   600] Species loss: 0.035; Genera loss: 0.101\n",
            "Epoch 20/100 Validation genera Loss: 3.626\n",
            "[21,   200] Species loss: 0.062; Genera loss: 0.070\n",
            "[21,   400] Species loss: 0.051; Genera loss: 0.072\n",
            "[21,   600] Species loss: 0.092; Genera loss: 0.084\n",
            "Epoch 21/100 Validation genera Loss: 3.720\n",
            "[22,   200] Species loss: 0.037; Genera loss: 0.080\n",
            "[22,   400] Species loss: 0.069; Genera loss: 0.065\n",
            "[22,   600] Species loss: 0.034; Genera loss: 0.046\n",
            "Epoch 22/100 Validation genera Loss: 3.203\n",
            "Early stopping at epoch 22\n",
            "Validation accuracy: 0.8497640984935112. Parameters: lr=0.01, threshold=0.7, \n",
            "Validation accuracy: 0.8473253135699528. Parameters: lr=0.01, threshold=0.7049152542372881, \n",
            "Validation accuracy: 0.8463272929884422. Parameters: lr=0.01, threshold=0.7098305084745762, \n",
            "Validation accuracy: 0.8441753206120912. Parameters: lr=0.01, threshold=0.7147457627118644, \n",
            "Validation accuracy: 0.8423541838198386. Parameters: lr=0.01, threshold=0.7196610169491525, \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[60], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m train(model, lr, momentum, max_epochs, batch_size, print_losses\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m threshold_values:\n\u001b[0;32m---> 15\u001b[0m     validation_species_accuracy, validation_genera_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     validation_loss \u001b[38;5;241m=\u001b[39m validation_species_accuracy \u001b[38;5;241m+\u001b[39m validation_genera_accuracy\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m((\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalidation_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameters: lr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreshold=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthreshold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m             ))\n",
            "Cell \u001b[0;32mIn[57], line 36\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(model, threshold, batch_size)\u001b[0m\n\u001b[1;32m     33\u001b[0m     correct_predictions_per_labels[species[idx]\u001b[38;5;241m.\u001b[39mitem()] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# if the sample is of one undescribed species\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m species[idx]\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseen_species\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m genera[idx]\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39munique(validation_set\u001b[38;5;241m.\u001b[39munseen_species_genera)\n\u001b[1;32m     38\u001b[0m     total_samples_per_genera[genera[idx]\u001b[38;5;241m.\u001b[39mitem()] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[0;32m~/Development/PyTorch/lib/python3.11/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
            "File \u001b[0;32m~/Development/PyTorch/lib/python3.11/site-packages/numpy/lib/arraysetops.py:323\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    319\u001b[0m     output \u001b[38;5;241m=\u001b[39m (reshape_uniq(output[\u001b[38;5;241m0\u001b[39m]),) \u001b[38;5;241m+\u001b[39m output[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(output)\n\u001b[0;32m--> 323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_unique1d\u001b[39m(ar, return_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    324\u001b[0m               return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, equal_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    325\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m    Find the unique elements of an array, ignoring shape.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    328\u001b[0m     ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\u001b[38;5;241m.\u001b[39mflatten()\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "lr_values = [0.01]\n",
        "threshold_values = np.linspace(0.7, 0.99, 60)\n",
        "momentum = 0.9\n",
        "batch_size = 16\n",
        "max_epochs = 100\n",
        "\n",
        "best_validation_accuracy = 0\n",
        "best_parameters = {}\n",
        "\n",
        "for lr in lr_values:\n",
        "    model = AttentionNet(652, 368)\n",
        "    model.to(device)\n",
        "    train(model, lr, momentum, max_epochs, batch_size, print_losses=True)\n",
        "    for threshold in threshold_values:\n",
        "        validation_species_accuracy, validation_genera_accuracy = validate(model, threshold, batch_size)\n",
        "        validation_loss = validation_species_accuracy + validation_genera_accuracy\n",
        "        print((f\"Validation accuracy: {validation_loss}. \"\n",
        "                f\"Parameters: lr={lr}, \"\n",
        "                f\"threshold={threshold}, \"\n",
        "                ))\n",
        "\n",
        "        if validation_loss > best_validation_accuracy:\n",
        "            best_validation_accuracy = validation_loss\n",
        "            best_parameters = {\n",
        "                'learning_rate': lr,\n",
        "                'threshold': threshold,\n",
        "            }\n",
        "\n",
        "print(\"Best parameters:\", best_parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final model training\n",
        "We select the best parameters found in the model selection section to train the final model on training and validation set.\n",
        "The model is then tested on the test set, which has $797$ seen species."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJgoWU0AusZr",
        "outputId": "69ce2de9-42cf-4a2a-ae95-7aedb040c2d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,   200] Species loss: 5.159; Genera loss: 3.587\n",
            "[1,   400] Species loss: 3.192; Genera loss: 1.867\n",
            "[1,   600] Species loss: 2.130; Genera loss: 1.204\n",
            "[1,   800] Species loss: 1.496; Genera loss: 0.827\n",
            "[1,  1000] Species loss: 0.999; Genera loss: 0.585\n",
            "[1,  1200] Species loss: 0.612; Genera loss: 0.396\n",
            "[2,   200] Species loss: 0.271; Genera loss: 0.188\n",
            "[2,   400] Species loss: 0.176; Genera loss: 0.133\n",
            "[2,   600] Species loss: 0.107; Genera loss: 0.100\n",
            "[2,   800] Species loss: 0.067; Genera loss: 0.073\n",
            "[2,  1000] Species loss: 0.055; Genera loss: 0.049\n",
            "[2,  1200] Species loss: 0.047; Genera loss: 0.054\n",
            "[3,   200] Species loss: 0.028; Genera loss: 0.033\n",
            "[3,   400] Species loss: 0.029; Genera loss: 0.028\n",
            "[3,   600] Species loss: 0.017; Genera loss: 0.024\n",
            "[3,   800] Species loss: 0.019; Genera loss: 0.025\n",
            "[3,  1000] Species loss: 0.021; Genera loss: 0.023\n",
            "[3,  1200] Species loss: 0.012; Genera loss: 0.023\n",
            "[4,   200] Species loss: 0.009; Genera loss: 0.018\n",
            "[4,   400] Species loss: 0.010; Genera loss: 0.013\n",
            "[4,   600] Species loss: 0.013; Genera loss: 0.017\n",
            "[4,   800] Species loss: 0.012; Genera loss: 0.014\n",
            "[4,  1000] Species loss: 0.012; Genera loss: 0.012\n",
            "[4,  1200] Species loss: 0.008; Genera loss: 0.011\n",
            "[5,   200] Species loss: 0.005; Genera loss: 0.008\n",
            "[5,   400] Species loss: 0.015; Genera loss: 0.009\n",
            "[5,   600] Species loss: 0.005; Genera loss: 0.008\n",
            "[5,   800] Species loss: 0.007; Genera loss: 0.008\n",
            "[5,  1000] Species loss: 0.004; Genera loss: 0.009\n",
            "[5,  1200] Species loss: 0.010; Genera loss: 0.007\n",
            "[6,   200] Species loss: 0.003; Genera loss: 0.004\n",
            "[6,   400] Species loss: 0.004; Genera loss: 0.005\n",
            "[6,   600] Species loss: 0.004; Genera loss: 0.008\n",
            "[6,   800] Species loss: 0.004; Genera loss: 0.005\n",
            "[6,  1000] Species loss: 0.004; Genera loss: 0.006\n",
            "[6,  1200] Species loss: 0.003; Genera loss: 0.005\n",
            "[7,   200] Species loss: 0.003; Genera loss: 0.004\n",
            "[7,   400] Species loss: 0.004; Genera loss: 0.006\n",
            "[7,   600] Species loss: 0.003; Genera loss: 0.004\n",
            "[7,   800] Species loss: 0.002; Genera loss: 0.004\n",
            "[7,  1000] Species loss: 0.003; Genera loss: 0.007\n",
            "[7,  1200] Species loss: 0.003; Genera loss: 0.010\n",
            "[8,   200] Species loss: 0.003; Genera loss: 0.003\n",
            "[8,   400] Species loss: 0.002; Genera loss: 0.003\n",
            "[8,   600] Species loss: 0.003; Genera loss: 0.004\n",
            "[8,   800] Species loss: 0.003; Genera loss: 0.003\n",
            "[8,  1000] Species loss: 0.002; Genera loss: 0.003\n",
            "[8,  1200] Species loss: 0.002; Genera loss: 0.004\n",
            "[9,   200] Species loss: 0.001; Genera loss: 0.003\n",
            "[9,   400] Species loss: 0.002; Genera loss: 0.003\n",
            "[9,   600] Species loss: 0.001; Genera loss: 0.003\n",
            "[9,   800] Species loss: 0.003; Genera loss: 0.003\n",
            "[9,  1000] Species loss: 0.002; Genera loss: 0.005\n",
            "[9,  1200] Species loss: 0.001; Genera loss: 0.003\n",
            "[10,   200] Species loss: 0.001; Genera loss: 0.002\n",
            "[10,   400] Species loss: 0.002; Genera loss: 0.004\n",
            "[10,   600] Species loss: 0.002; Genera loss: 0.003\n",
            "[10,   800] Species loss: 0.001; Genera loss: 0.002\n",
            "[10,  1000] Species loss: 0.001; Genera loss: 0.003\n",
            "[10,  1200] Species loss: 0.001; Genera loss: 0.002\n",
            "-------------------------------------------------------------------------------\n",
            "Final model described species accuracy:  0.988119227179433\n",
            "Final model undescribed species accuracy:  0.6972008363717906\n",
            "-------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = AttentionNet(797, 368)\n",
        "model.to(device)\n",
        "train(model, best_parameters['learning_rate'], momentum, 10, batch_size, train_val=True, print_losses=True)\n",
        "species_accuracy, genera_accuracy = test(model, best_parameters['threshold'], batch_size)\n",
        "\n",
        "print(\"-------------------------------------------------------------------------------\")\n",
        "print(f\"Final model described species accuracy: \", species_accuracy)\n",
        "print(f\"Final model undescribed species accuracy: \", genera_accuracy)\n",
        "print(\"-------------------------------------------------------------------------------\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
