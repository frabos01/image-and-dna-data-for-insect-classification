{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z8o3HBAmspak"
      },
      "outputs": [],
      "source": [
        "!wget https://dataworks.indianapolis.iu.edu/bitstream/handle/11243/41/data.zip\n",
        "!unzip -q data.zip\n",
        "!rm data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTwIpTTYsaIR",
        "outputId": "1d33d159-8db0-4c0a-c042-311c07b15310"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "import scipy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from functools import reduce\n",
        "\n",
        "torch.manual_seed(0)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Pc1BZG2saIW"
      },
      "source": [
        "# Dataset definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "n4jHfAYRsaIY"
      },
      "outputs": [],
      "source": [
        "class ImageDNATrainDataset():\n",
        "    def __init__(self, train=True):\n",
        "        splits_mat = scipy.io.loadmat(\"data/INSECTS/splits.mat\")\n",
        "        train_loc = splits_mat[\"train_loc\"]-1\n",
        "\n",
        "        TRAINING_SAMPLES_NUMBER = 12481\n",
        "        TRAINING_LABELS_NUMBER = 652\n",
        "\n",
        "        assert len(train_loc[0]) == TRAINING_SAMPLES_NUMBER\n",
        "\n",
        "        indeces = train_loc\n",
        "        # indeces.shape is (1, |indeces|), so we extract the whole list using [0]\n",
        "        indeces = indeces[0]\n",
        "\n",
        "        data_mat = scipy.io.loadmat(\"data/INSECTS/data.mat\")\n",
        "        self.embeddings_img = torch.from_numpy(\n",
        "            data_mat[\"embeddings_img\"][indeces]\n",
        "        ).float()\n",
        "        self.embeddings_dna = torch.from_numpy(\n",
        "            data_mat[\"embeddings_dna\"][indeces]\n",
        "        ).float()\n",
        "\n",
        "        # Remap seen species in [0, 651]\n",
        "        seen_species = data_mat[\"labels\"][train_loc][0]\n",
        "        seen_species_mapping = {label: i for i, label in enumerate(np.unique(seen_species))}\n",
        "\n",
        "        species_mapping = seen_species_mapping\n",
        "        assert len(species_mapping) == TRAINING_LABELS_NUMBER\n",
        "\n",
        "        species = data_mat[\"labels\"][indeces]\n",
        "        remapped_species = np.array([species_mapping[label.item()] for label in species])\n",
        "        self.remapped_species = torch.from_numpy(remapped_species).long()\n",
        "\n",
        "        assert len(torch.unique(self.remapped_species)) == TRAINING_LABELS_NUMBER\n",
        "\n",
        "        # data_mat['G'] returns a ndarray of type uint16, therefore we convert into int16 before invoking from_numpy\n",
        "        self.G = torch.from_numpy(data_mat[\"G\"].astype(np.int16)).long()\n",
        "        self.genera = torch.empty(species.shape).long()\n",
        "        for i in range(indeces.size):\n",
        "            self.genera[i][0] = self.G[species[i][0] - 1][0] - 1041\n",
        "\n",
        "        assert len(self.genera) == TRAINING_SAMPLES_NUMBER\n",
        "\n",
        "        self.species_names = data_mat[\"species\"][indeces]\n",
        "        self.ids = data_mat[\"ids\"][indeces]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.embeddings_dna)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        embedding_img = self.embeddings_img[idx]\n",
        "        embedding_dna = self.embeddings_dna[idx]\n",
        "        label = self.remapped_species[idx].item()\n",
        "        genera = self.genera[idx].item()\n",
        "\n",
        "        return embedding_img.view(1, -1), embedding_dna.view(1, -1), label, genera"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validation set\n",
        "- Number of samples: 6939.\n",
        "- Number of seen species of the training set in the validation set: 629.\n",
        "- Number of unseen species in the validation set: 97"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GasJN0zyusZi"
      },
      "outputs": [],
      "source": [
        "class ImageDNAValidationDataset():\n",
        "    def __init__(self, train=True):\n",
        "        splits_mat = scipy.io.loadmat(\"data/INSECTS/splits.mat\")\n",
        "        train_loc = splits_mat[\"train_loc\"]-1\n",
        "        val_seen_loc = splits_mat[\"val_seen_loc\"]-1\n",
        "        val_unseen_loc = splits_mat[\"val_unseen_loc\"]-1\n",
        "\n",
        "        TRAINING_LABELS_NUMBER = 652\n",
        "        VALIDATION_SAMPLES_NUMBER = 6939\n",
        "        VALIDATION_SPECIES_NUMBER = 774\n",
        "        TRAINING_VALIDATION_SPECIES_NUMBER = 797\n",
        "        VALIDATION_SEEN_SPECIES_NUMBER = 629\n",
        "        VALIDATION_UNSEEN_SPECIES_GENERA_NUMBER = 97\n",
        "\n",
        "        indeces = np.concatenate((val_seen_loc, val_unseen_loc), axis=1)\n",
        "        # indeces.shape is (1, |indeces|), so we extract the whole list using [0]\n",
        "        indeces = indeces[0]\n",
        "        assert len(indeces) == VALIDATION_SAMPLES_NUMBER\n",
        "\n",
        "        data_mat = scipy.io.loadmat(\"data/INSECTS/data.mat\")\n",
        "        self.embeddings_img = torch.from_numpy(data_mat[\"embeddings_img\"][indeces]).float()\n",
        "        self.embeddings_dna = torch.from_numpy(data_mat[\"embeddings_dna\"][indeces]).float()\n",
        "\n",
        "        # Remap seen species in [0, 651]\n",
        "        seen_species = data_mat[\"labels\"][train_loc][0]\n",
        "        seen_species_mapping = {label: i for i, label in enumerate(np.unique(seen_species))}\n",
        "\n",
        "        # Remap unseen species during validation in [652, 796]\n",
        "        unseen_species = data_mat[\"labels\"][val_unseen_loc][0]\n",
        "        unseen_species_mapping = {label: i + TRAINING_LABELS_NUMBER for i, label in enumerate(np.unique(unseen_species))}\n",
        "\n",
        "        # Union of the two mappings, allows to fully remap all the labels\n",
        "        species_mapping = seen_species_mapping | unseen_species_mapping\n",
        "        assert len(species_mapping) == TRAINING_VALIDATION_SPECIES_NUMBER\n",
        "\n",
        "        species = data_mat[\"labels\"][indeces]\n",
        "        remapped_species = np.array([species_mapping[label.item()] for label in species])\n",
        "        self.remapped_species = torch.from_numpy(remapped_species).long()\n",
        "        assert len(torch.unique(self.remapped_species)) == VALIDATION_SPECIES_NUMBER\n",
        "\n",
        "        # data_mat['G'] returns a ndarray of type uint16, therefore we convert into int16 before invoking from_numpy\n",
        "        self.G = torch.from_numpy(data_mat[\"G\"].astype(np.int16)).long()\n",
        "        self.genera = torch.empty(species.shape).long()\n",
        "        for i in range(indeces.size):\n",
        "            self.genera[i][0] = self.G[species[i][0] - 1][0] - 1041\n",
        "\n",
        "        # Compute genera of unseen species in the validation set\n",
        "        unseen_species_genera = []\n",
        "        for i in val_unseen_loc[0]:\n",
        "            unseen_species_genera.append(data_mat[\"G\"][data_mat[\"labels\"][i][0] - 1][0] - 1041)\n",
        "        self.unseen_species_genera = np.array(unseen_species_genera)\n",
        "        assert len(np.unique(self.unseen_species_genera)) == VALIDATION_UNSEEN_SPECIES_GENERA_NUMBER\n",
        "\n",
        "        # Compute seen species number in the validation set\n",
        "        seen_species = []\n",
        "        for i in val_seen_loc[0]:\n",
        "            seen_species.append(species_mapping[data_mat[\"labels\"][i].item()])\n",
        "        self.seen_species = np.array(seen_species)\n",
        "        assert len(np.unique(self.seen_species)) == VALIDATION_SEEN_SPECIES_NUMBER\n",
        "\n",
        "        self.species_names = data_mat[\"species\"][indeces]\n",
        "        self.ids = data_mat[\"ids\"][indeces]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.embeddings_dna)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        embedding_img = self.embeddings_img[idx]\n",
        "        embedding_dna = self.embeddings_dna[idx]\n",
        "        label = self.remapped_species[idx].item()\n",
        "        genera = self.genera[idx].item()\n",
        "\n",
        "        return embedding_img.view(1, -1), embedding_dna.view(1, -1), label, genera"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test set\n",
        "- Number of samples: 13428.\n",
        "- Number of seen species of the training and validation set in the test set: 770.\n",
        "- Number of unseen species in the test set: 134"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MKdIHeWZusZj"
      },
      "outputs": [],
      "source": [
        "class ImageDNATestDataset(Dataset):\n",
        "    def __init__(self, train=True):\n",
        "        splits_mat = scipy.io.loadmat(\"data/INSECTS/splits.mat\")\n",
        "        train_loc = splits_mat[\"train_loc\"]-1\n",
        "        trainval_loc = splits_mat[\"trainval_loc\"]-1\n",
        "        test_seen_loc = splits_mat[\"test_seen_loc\"]-1\n",
        "        test_unseen_loc = splits_mat[\"test_unseen_loc\"]-1\n",
        "        val_seen_loc = splits_mat[\"val_seen_loc\"]-1\n",
        "        val_unseen_loc = splits_mat[\"val_unseen_loc\"]-1\n",
        "\n",
        "        TRAINING_SPECIES_NUMBER = 652\n",
        "        TRAINING_VALIDATION_SPECIES = 797\n",
        "        NUMBER_OF_SPECIES = 1040\n",
        "        TEST_SEEN_SPECIES_NUMBER = 770\n",
        "        TEST_UNSEEN_SPECIES_GENERA_NUMBER = 134\n",
        "\n",
        "        indeces = np.concatenate((test_seen_loc, test_unseen_loc), axis=1)\n",
        "        # indeces.shape is (1, |indeces|), so we extract the whole list using [0]\n",
        "        indeces = indeces[0]\n",
        "\n",
        "        data_mat = scipy.io.loadmat(\"data/INSECTS/data.mat\")\n",
        "        self.embeddings_img = torch.from_numpy(data_mat[\"embeddings_img\"][indeces]).float()\n",
        "        self.embeddings_dna = torch.from_numpy(data_mat[\"embeddings_dna\"][indeces]).float()\n",
        "\n",
        "        # Remap seen species in [0, 651]\n",
        "        seen_species = data_mat[\"labels\"][train_loc][0]\n",
        "        seen_species_mapping = {label: i for i, label in enumerate(np.unique(seen_species))}\n",
        "\n",
        "        # Remap unseen species during validation in [652, 796]\n",
        "        unseen_species_validation = data_mat[\"labels\"][val_unseen_loc][0]\n",
        "        unseen_species_validation_mapping = {label: i + TRAINING_SPECIES_NUMBER for i, label in enumerate(np.unique(unseen_species_validation))}\n",
        "\n",
        "        # Remap unseen species during test in [797, 1039]\n",
        "        unseen_species_test = data_mat[\"labels\"][test_unseen_loc][0]\n",
        "        unseen_species_test_mapping = {label: i + TRAINING_VALIDATION_SPECIES for i, label in enumerate(np.unique(unseen_species_test))}\n",
        "\n",
        "        assert reduce(np.intersect1d, (seen_species, unseen_species_validation, unseen_species_test)).size == 0\n",
        "\n",
        "        # Union of the two mappings, allows to full remap all the labels\n",
        "        labels_mapping = seen_species_mapping | unseen_species_validation_mapping | unseen_species_test_mapping\n",
        "        assert len(labels_mapping) == NUMBER_OF_SPECIES\n",
        "\n",
        "        species = data_mat[\"labels\"][indeces]\n",
        "        remapped_labels = np.array([labels_mapping[label.item()] for label in species])\n",
        "        self.remapped_labels = torch.from_numpy(remapped_labels).long()\n",
        "\n",
        "        # data_mat['G'] returns a ndarray of type uint16, therefore we convert into int16 before invoking from_numpy\n",
        "        self.G = torch.from_numpy(data_mat[\"G\"].astype(np.int16)).long()\n",
        "        self.genera = torch.empty(species.shape).long()\n",
        "        for i in range(indeces.size):\n",
        "            self.genera[i][0] = self.G[species[i][0] - 1][0] - 1041\n",
        "\n",
        "        # Compute genera of unseen species\n",
        "        unseen_species_genera = []\n",
        "        for i in test_unseen_loc[0]:\n",
        "            unseen_species_genera.append(data_mat[\"G\"][data_mat[\"labels\"][i][0] - 1][0] - 1041)\n",
        "\n",
        "        self.unseen_species_genera = np.array(unseen_species_genera)\n",
        "        assert len(np.unique(self.unseen_species_genera)) == TEST_UNSEEN_SPECIES_GENERA_NUMBER\n",
        "\n",
        "        # Compute seen species\n",
        "        seen_species = []\n",
        "        for i in test_seen_loc[0]:\n",
        "            seen_species.append(labels_mapping[data_mat[\"labels\"][i].item()])\n",
        "        self.seen_species = np.array(seen_species)\n",
        "        assert len(np.unique(self.seen_species)) == TEST_SEEN_SPECIES_NUMBER\n",
        "\n",
        "        self.species_name = data_mat[\"species\"][indeces]\n",
        "        self.ids = data_mat[\"ids\"][indeces]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.embeddings_dna)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        embedding_img = self.embeddings_img[idx]\n",
        "        embedding_dna = self.embeddings_dna[idx]\n",
        "        label = self.remapped_labels[idx].item()\n",
        "        genera = self.genera[idx].item()\n",
        "\n",
        "        return embedding_img.view(1, -1), embedding_dna.view(1, -1), label, genera"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PWLG3L3eusZl"
      },
      "outputs": [],
      "source": [
        "class ImageDNATrainValidationDataset(Dataset):\n",
        "    def __init__(self, train=True):\n",
        "        splits_mat = scipy.io.loadmat(\"data/INSECTS/splits.mat\")\n",
        "        train_loc = splits_mat[\"train_loc\"]-1\n",
        "        trainval_loc = splits_mat[\"trainval_loc\"]-1\n",
        "        test_seen_loc = splits_mat[\"test_seen_loc\"]-1\n",
        "        test_unseen_loc = splits_mat[\"test_unseen_loc\"]-1\n",
        "        val_seen_loc = splits_mat[\"val_seen_loc\"]-1\n",
        "        val_unseen_loc = splits_mat[\"val_unseen_loc\"]-1\n",
        "\n",
        "        TRAINING_SPECIES_NUMBER = 652\n",
        "        TRAINING_VALIDATION_SPECIES = 797\n",
        "        NUMBER_OF_SPECIES = 1040\n",
        "\n",
        "        indeces = trainval_loc\n",
        "        # indeces.shape is (1, |indeces|), so we extract the whole list using [0]\n",
        "        indeces = indeces[0]\n",
        "\n",
        "        data_mat = scipy.io.loadmat(\"data/INSECTS/data.mat\")\n",
        "        self.embeddings_img = torch.from_numpy(data_mat[\"embeddings_img\"][indeces]).float()\n",
        "        self.embeddings_dna = torch.from_numpy(data_mat[\"embeddings_dna\"][indeces]).float()\n",
        "\n",
        "        # Remap seen species in [0, 651]\n",
        "        seen_species = data_mat[\"labels\"][train_loc][0]\n",
        "        seen_species_mapping = {label: i for i, label in enumerate(np.unique(seen_species))}\n",
        "\n",
        "        # Remap unseen species during validation in [652, 796]\n",
        "        unseen_species_validation = data_mat[\"labels\"][val_unseen_loc][0]\n",
        "        unseen_species_validation_mapping = {label: i + TRAINING_SPECIES_NUMBER for i, label in enumerate(np.unique(unseen_species_validation))}\n",
        "\n",
        "        # Remap unseen species during test in [797, 1039]\n",
        "        unseen_species_test = data_mat[\"labels\"][test_unseen_loc][0]\n",
        "        unseen_species_test_mapping = {label: i + TRAINING_VALIDATION_SPECIES for i, label in enumerate(np.unique(unseen_species_test))}\n",
        "\n",
        "        assert reduce(np.intersect1d, (seen_species, unseen_species_validation, unseen_species_test)).size == 0\n",
        "\n",
        "        # Union of the two mappings, allows to full remap all the labels\n",
        "        labels_mapping = seen_species_mapping | unseen_species_validation_mapping | unseen_species_test_mapping\n",
        "        assert len(labels_mapping) == NUMBER_OF_SPECIES\n",
        "\n",
        "        species = data_mat[\"labels\"][indeces]  # Consider only train\n",
        "        remapped_labels = np.array([labels_mapping[label.item()] for label in species])\n",
        "        self.remapped_labels = torch.from_numpy(remapped_labels).long()\n",
        "\n",
        "        assert len(torch.unique(self.remapped_labels)) == TRAINING_VALIDATION_SPECIES\n",
        "\n",
        "        # data_mat['G'] returns a ndarray of type uint16, therefore we convert into int16 before invoking from_numpy\n",
        "        self.G = torch.from_numpy(data_mat[\"G\"].astype(np.int16)).long()\n",
        "        self.genera = torch.empty(species.shape).long()\n",
        "        for i in range(indeces.size):\n",
        "            self.genera[i][0] = self.G[species[i][0] - 1][0] - 1041\n",
        "\n",
        "        self.species = data_mat[\"species\"][indeces]\n",
        "        self.ids = data_mat[\"ids\"][indeces]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.embeddings_dna)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        embedding_img = self.embeddings_img[idx]\n",
        "        embedding_dna = self.embeddings_dna[idx]\n",
        "        label = self.remapped_labels[idx].item()\n",
        "        genera = self.genera[idx].item()\n",
        "\n",
        "        return embedding_img.view(1, -1), embedding_dna.view(1, -1), label, genera\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg3l8IA0saIb"
      },
      "source": [
        "# Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fp_osQc7usZm"
      },
      "outputs": [],
      "source": [
        "class AttentionNet(nn.Module):\n",
        "        def __init__(self, num_seen_species, num_genera, embed_dim_1, num_heads_1, embed_dim_2, num_heads_2, embed_dim_3, num_heads_3):\n",
        "                super(AttentionNet, self).__init__()\n",
        "\n",
        "                self.img_fc1 = nn.Linear(2048, 1024)\n",
        "                self.img_fc2 = nn.Linear(1024, 500)\n",
        "\n",
        "                self.inception_encoders_block_1 = InceptionEncodersBlock(embed_dim_1, num_heads_1, embed_dim_2, num_heads_2, embed_dim_3, num_heads_3)\n",
        "\n",
        "                self.fc_species_1 = nn.Linear(4000, 1000)\n",
        "                self.fc_species_2 = nn.Linear(1000, num_seen_species)\n",
        "\n",
        "                self.fc_genera_1 = nn.Linear(4000, 500)\n",
        "                self.fc_genera_2 = nn.Linear(500, num_genera)\n",
        "\n",
        "                self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "\n",
        "        def forward(self, x_img, x_dna):\n",
        "                x_img = F.relu(self.img_fc1(x_img))\n",
        "                x_img = self.img_fc2(x_img)\n",
        "\n",
        "                x_img, x_dna = self.inception_encoders_block_1(x_img, x_dna)\n",
        "\n",
        "                x = torch.cat((x_img, x_dna), axis=1)\n",
        "\n",
        "                x_species = x.clone()\n",
        "                x_genera = x.clone()\n",
        "\n",
        "                x_species = self.dropout(F.relu(self.fc_species_1(x_species)))\n",
        "                x_species = self.fc_species_2(x_species)\n",
        "\n",
        "                x_genera = self.dropout(F.relu(self.fc_genera_1(x_genera)))\n",
        "                x_genera = self.fc_genera_2(x_genera)\n",
        "\n",
        "                return x_species, x_genera\n",
        "\n",
        "class ImageDNAEncoder(nn.Module):\n",
        "        def __init__(self, embed_dim, linear_dim, num_heads):\n",
        "                super(ImageDNAEncoder, self).__init__()\n",
        "                self.multi_head_img_1 = nn.MultiheadAttention(embed_dim, num_heads)\n",
        "                self.multi_head_dna_1 = nn.MultiheadAttention(embed_dim, num_heads)\n",
        "\n",
        "                self.norm_img_1 = nn.LayerNorm(embed_dim)\n",
        "                self.norm_dna_1 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "                self.linear_img_1 = nn.Linear(embed_dim, linear_dim)\n",
        "                self.dropout_img = nn.Dropout(0.5)\n",
        "                self.linear_img_2 = nn.Linear(linear_dim, embed_dim)\n",
        "\n",
        "                self.linear_dna_1 = nn.Linear(embed_dim, linear_dim)\n",
        "                self.dropout_dna = nn.Dropout(0.5)\n",
        "                self.linear_dna_2 = nn.Linear(linear_dim, embed_dim)\n",
        "\n",
        "\n",
        "        def forward(self, x_img, x_dna):\n",
        "                identity = x_img\n",
        "                x_img, _ = self.multi_head_img_1(x_img, x_dna, x_dna)\n",
        "                x_img = self.norm_img_1(x_img + identity)\n",
        "                x_img = self.feed_forward_img(x_img)\n",
        "\n",
        "                identity = x_dna\n",
        "                x_dna, _ = self.multi_head_dna_1(x_dna, x_img, x_img)\n",
        "                x_dna = self.norm_dna_1(x_dna + identity)\n",
        "                x_dna = self.feed_forward_dna(x_dna)\n",
        "\n",
        "                return x_img, x_dna\n",
        "\n",
        "        def feed_forward_img(self, x):\n",
        "                return self.linear_img_2(self.dropout_img(F.relu(self.linear_img_1(x))))\n",
        "\n",
        "        def feed_forward_dna(self, x):\n",
        "                return self.linear_dna_2(self.dropout_dna(F.relu(self.linear_dna_1(x))))\n",
        "\n",
        "class InceptionEncodersBlock(nn.Module):\n",
        "        def __init__(self, embed_dim_1, num_heads_1, embed_dim_2, num_heads_2, embed_dim_3, num_heads_3):\n",
        "                super(InceptionEncodersBlock, self).__init__()\n",
        "                self.img_dna_encoder_1 = ImageDNAEncoder(embed_dim_1, 4 * embed_dim_1, num_heads_1)\n",
        "                self.img_dna_encoder_2 = ImageDNAEncoder(embed_dim_2, 4 * embed_dim_2, num_heads_2)\n",
        "                self.img_dna_encoder_3 = ImageDNAEncoder(embed_dim_3, 4 * embed_dim_3, num_heads_3)\n",
        "\n",
        "                self.INPUT_SIZE = 500\n",
        "                self.embed_dim_1 = embed_dim_1\n",
        "                self.num_heads_1 = num_heads_1\n",
        "                self.embed_dim_2 = embed_dim_2\n",
        "                self.num_heads_2 = num_heads_2\n",
        "                self.embed_dim_3 = embed_dim_3\n",
        "                self.num_heads_3 = num_heads_3\n",
        "\n",
        "        def forward(self, x_img, x_dna):\n",
        "\n",
        "                img_identity = torch.reshape(x_img.clone(), (-1, self.INPUT_SIZE ))\n",
        "                dna_identity = torch.reshape(x_dna.clone(), (-1, self.INPUT_SIZE ))\n",
        "                x_img_1 = torch.reshape(x_img.clone(), (-1, self.INPUT_SIZE // self.embed_dim_1, self.embed_dim_1))\n",
        "                x_dna_1 = torch.reshape(x_dna.clone(), (-1, self.INPUT_SIZE // self.embed_dim_1, self.embed_dim_1))\n",
        "                x_img_2 = torch.reshape(x_img.clone(), (-1, self.INPUT_SIZE // self.embed_dim_2, self.embed_dim_2))\n",
        "                x_dna_2 = torch.reshape(x_dna.clone(), (-1, self.INPUT_SIZE // self.embed_dim_2, self.embed_dim_2))\n",
        "                x_img_3 = torch.reshape(x_img.clone(), (-1, self.INPUT_SIZE // self.embed_dim_3, self.embed_dim_3))\n",
        "                x_dna_3 = torch.reshape(x_dna.clone(), (-1, self.INPUT_SIZE // self.embed_dim_3, self.embed_dim_3))\n",
        "\n",
        "                x_img_1, x_dna_1 = self.img_dna_encoder_1(x_img_1, x_dna_1)\n",
        "                x_img_2, x_dna_2 = self.img_dna_encoder_2(x_img_2, x_dna_2)\n",
        "                x_img_3, x_dna_3 = self.img_dna_encoder_3(x_img_3, x_dna_3)\n",
        "\n",
        "                x_img_1 = torch.reshape(x_img_1, (-1, self.INPUT_SIZE))\n",
        "                x_dna_1 = torch.reshape(x_dna_1, (-1, self.INPUT_SIZE))\n",
        "                x_img_2 = torch.reshape(x_img_2, (-1, self.INPUT_SIZE))\n",
        "                x_dna_2 = torch.reshape(x_dna_2, (-1, self.INPUT_SIZE))\n",
        "                x_img_3 = torch.reshape(x_img_3, (-1, self.INPUT_SIZE))\n",
        "                x_dna_3 = torch.reshape(x_dna_3, (-1, self.INPUT_SIZE))\n",
        "\n",
        "                x_img = img_identity + x_img_1 + x_img_2 + x_img_3\n",
        "                x_dna = dna_identity + x_dna_1 + x_dna_2 + x_dna_3\n",
        "\n",
        "                x_img = torch.concat((img_identity, x_img_1, x_img_2, x_img_3), axis=1)\n",
        "                x_dna = torch.concat((dna_identity, x_dna_1, x_dna_2, x_dna_3), axis=1)\n",
        "\n",
        "                return x_img, x_dna\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEj9iqWHsaId"
      },
      "source": [
        "# Creating datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Of4Mq0hKsaId"
      },
      "outputs": [],
      "source": [
        "training_set = ImageDNATrainDataset()\n",
        "validation_set = ImageDNAValidationDataset()\n",
        "test_set = ImageDNATestDataset()\n",
        "training_validation_set = ImageDNATrainValidationDataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c93Uli0msaIe"
      },
      "source": [
        "Defining methods for training, validating and testing the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dm6_gk-JusZo"
      },
      "outputs": [],
      "source": [
        "def train(model, lr, momentum, num_epochs, batch_size, train_val=False, print_losses=False, print_step = 200):\n",
        "    model.train()\n",
        "    criterion_species = torch.nn.CrossEntropyLoss()\n",
        "    criterion_genera = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "    if train_val:\n",
        "        loader = torch.utils.data.DataLoader(training_validation_set, batch_size=batch_size, shuffle=True)\n",
        "    else:\n",
        "        loader = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        running_labels_loss = 0.0\n",
        "        running_genera_loss = 0.0\n",
        "\n",
        "        for i, data in enumerate(loader, 0):\n",
        "            inputs_img, inputs_dna, species, genera = data\n",
        "            inputs_img, inputs_dna, species, genera = inputs_img.to(device), inputs_dna.to(device), species.to(device), genera.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            labels_outputs, genera_outputs = model(inputs_img, inputs_dna)\n",
        "            labels_loss = criterion_species(labels_outputs, species)\n",
        "            genera_loss = criterion_genera(genera_outputs, genera)\n",
        "            total_loss = labels_loss + genera_loss\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Print losses\n",
        "            if print_losses:\n",
        "                running_labels_loss += labels_loss.item()\n",
        "                running_genera_loss += genera_loss.item()\n",
        "                if i % print_step == print_step - 1:\n",
        "                    print(f\"[{epoch + 1}, {i + 1:5d}] Species loss: {running_labels_loss / print_step:.3f}; Genera loss: {running_genera_loss / print_step:.3f}\")\n",
        "                    running_labels_loss = 0.0\n",
        "                    running_genera_loss = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ti1M7rRAusZp"
      },
      "outputs": [],
      "source": [
        "def validate(model, threshold, batch_size):\n",
        "\n",
        "    validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=False)\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        correct_predictions_per_labels = defaultdict(int)\n",
        "        total_samples_per_labels = defaultdict(int)\n",
        "        correct_predictions_per_genera = defaultdict(int)\n",
        "        total_samples_per_genera = defaultdict(int)\n",
        "\n",
        "        for data in validation_loader:\n",
        "            inputs_img, inputs_dna, species, genera = data\n",
        "            inputs_img, inputs_dna, species, genera = inputs_img.to(device), inputs_dna.to(device), species.to(device), genera.to(device)\n",
        "\n",
        "            labels_outputs, genera_outputs = model(inputs_img, inputs_dna)\n",
        "\n",
        "            labels_outputs = nn.Softmax(dim=1)(labels_outputs)\n",
        "            genera_outputs = nn.Softmax(dim=1)(genera_outputs)\n",
        "\n",
        "            predicted_labels_values, predicted_labels = torch.topk(labels_outputs.data, k=2, dim=1)\n",
        "            _, predicted_genera = torch.max(genera_outputs.data, 1)\n",
        "\n",
        "            differences = predicted_labels_values[:, 0] - predicted_labels_values[:, 1]\n",
        "            genera_mask = differences <= threshold\n",
        "            labels_mask = ~genera_mask\n",
        "\n",
        "            # Update relative frequencies\n",
        "            for idx in range(len(genera)):\n",
        "                total_samples_per_labels[species[idx].item()] += 1\n",
        "\n",
        "                if labels_mask[idx] and predicted_labels[idx, 0] == species[idx]:\n",
        "                    correct_predictions_per_labels[species[idx].item()] += 1\n",
        "\n",
        "                # if the sample is of one undescribed species\n",
        "                if species[idx].item() not in np.unique(validation_set.seen_species):\n",
        "                    assert genera[idx].item() in np.unique(validation_set.unseen_species_genera)\n",
        "                    total_samples_per_genera[genera[idx].item()] += 1\n",
        "\n",
        "                    if genera_mask[idx] and predicted_genera[idx] == genera[idx]:\n",
        "                        correct_predictions_per_genera[genera[idx].item()] += 1\n",
        "\n",
        "        accuracy_per_label = {label: (correct_predictions_per_labels[label] / total_samples_per_labels[label]) if total_samples_per_labels[label] > 0 else 0 for label in total_samples_per_labels}\n",
        "        accuracy_per_genera = {genera: (correct_predictions_per_genera[genera] / total_samples_per_genera[genera]) if total_samples_per_genera[genera] > 0 else 0 for genera in total_samples_per_genera}\n",
        "\n",
        "        test_described_species_accuracy = 0\n",
        "        for label in np.unique(validation_set.seen_species):\n",
        "            test_described_species_accuracy += accuracy_per_label[label]\n",
        "\n",
        "        test_undescribed_species_accuracy = 0\n",
        "        for genera in np.unique(validation_set.unseen_species_genera):\n",
        "            test_undescribed_species_accuracy += accuracy_per_genera[genera]\n",
        "\n",
        "        normalized_test_described_species_accuracy = test_described_species_accuracy / 629\n",
        "        normalized_test_undescribed_species_accuracy = test_undescribed_species_accuracy / 97\n",
        "\n",
        "        return normalized_test_described_species_accuracy, normalized_test_undescribed_species_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "87_ldlBDusZp"
      },
      "outputs": [],
      "source": [
        "def test(model, threshold, batch_size):\n",
        "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        correct_predictions_per_labels = defaultdict(int)\n",
        "        total_samples_per_labels = defaultdict(int)\n",
        "        correct_predictions_per_genera = defaultdict(int)\n",
        "        total_samples_per_genera = defaultdict(int)\n",
        "\n",
        "        for data in test_loader:\n",
        "            inputs_img, inputs_dna, species, genera = data\n",
        "            inputs_img, inputs_dna, species, genera = inputs_img.to(device), inputs_dna.to(device), species.to(device), genera.to(device)\n",
        "\n",
        "            labels_outputs, genera_outputs = model(inputs_img, inputs_dna)\n",
        "\n",
        "            labels_outputs = nn.Softmax(dim=1)(labels_outputs)\n",
        "            genera_outputs = nn.Softmax(dim=1)(genera_outputs)\n",
        "\n",
        "            predicted_labels_values, predicted_labels = torch.topk(labels_outputs.data, k=2, dim=1)\n",
        "            _, predicted_genera = torch.max(genera_outputs.data, 1)\n",
        "\n",
        "            differences = predicted_labels_values[:, 0] - predicted_labels_values[:, 1]\n",
        "            genera_mask = differences <= threshold\n",
        "            labels_mask = ~genera_mask\n",
        "\n",
        "            # Update relative frequencies\n",
        "            for idx in range(len(genera)):\n",
        "                total_samples_per_labels[species[idx].item()] += 1\n",
        "\n",
        "                if labels_mask[idx] and predicted_labels[idx, 0] == species[idx]:\n",
        "                    correct_predictions_per_labels[species[idx].item()] += 1\n",
        "\n",
        "                # if the sample is of one undescribed species\n",
        "                if species[idx].item() not in np.unique(test_set.seen_species):\n",
        "                    assert genera[idx].item() in np.unique(test_set.unseen_species_genera)\n",
        "                    total_samples_per_genera[genera[idx].item()] += 1\n",
        "\n",
        "                    if genera_mask[idx] and predicted_genera[idx] == genera[idx]:\n",
        "                        correct_predictions_per_genera[genera[idx].item()] += 1\n",
        "\n",
        "        accuracy_per_label = {label: (correct_predictions_per_labels[label] / total_samples_per_labels[label]) if total_samples_per_labels[label] > 0 else 0 for label in total_samples_per_labels}\n",
        "        accuracy_per_genera = {genera: (correct_predictions_per_genera[genera] / total_samples_per_genera[genera]) if total_samples_per_genera[genera] > 0 else 0 for genera in total_samples_per_genera}\n",
        "\n",
        "        test_described_species_accuracy = 0\n",
        "        for label in np.unique(test_set.seen_species):\n",
        "            test_described_species_accuracy += accuracy_per_label[label]\n",
        "\n",
        "        test_undescribed_species_accuracy = 0\n",
        "        for genera in np.unique(test_set.unseen_species_genera):\n",
        "            test_undescribed_species_accuracy += accuracy_per_genera[genera]\n",
        "\n",
        "        normalized_test_described_species_accuracy = test_described_species_accuracy / 770\n",
        "        normalized_test_undescribed_species_accuracy = test_undescribed_species_accuracy / 134\n",
        "\n",
        "        return normalized_test_described_species_accuracy, normalized_test_undescribed_species_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model selection\n",
        "We tune the following hyperparameters through model selection:\n",
        "- Learning rate\n",
        "- Momentum\n",
        "- Batch size\n",
        "- Threshold\n",
        "- Embedding dimensions and number of heads of the inception block\n",
        "We select the values that maximizes the sum of seen species accuracy and unseen genera accuracy on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zItvqJfusZq",
        "outputId": "86c6e8bb-9703-41ff-e6a1-f04172f9451a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 1.4704879854513182. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.4733411655391906. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7049152542372881, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.4751747045111236. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7098305084745762, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.4768088004214615. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7147457627118644, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.479673362834993. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7196610169491525, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.4812700521211544. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7245762711864406, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.4820682424970397. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7294915254237287, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.483371978015068. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7344067796610169, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.4842468537641238. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7393220338983051, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.4855813348038633. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7442372881355932, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.4876853896540352. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7491525423728813, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.48950380166344. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7540677966101694, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.491004993821289. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7589830508474575, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.4929399336495384. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7638983050847458, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.4957281888502607. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7688135593220339, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.4973893465152153. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.773728813559322, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.4989736935562776. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7786440677966101, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5007326907215632. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7835593220338983, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5007326907215632. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7884745762711864, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5017622387218337. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7933898305084746, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.503927213402847. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7983050847457627, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.506325552463557. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8032203389830508, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.509057678139993. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8081355932203389, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5094037238468634. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8130508474576271, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5101803170256025. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8179661016949152, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.510935775996317. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8228813559322034, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.511288434579956. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8277966101694915, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5124701362670936. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8327118644067797, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5140419184354452. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8376271186440678, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5146645650740345. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8425423728813559, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5147719533901856. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.847457627118644, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5152355733527583. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8523728813559321, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5155877287084853. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8572881355932203, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.51589429274546. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8622033898305085, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5173177560033189. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8671186440677966, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5185084475087147. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8720338983050847, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5193903586963655. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8769491525423728, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5210425916528116. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.881864406779661, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5218384420158961. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8867796610169492, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.522231119331468. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8916949152542373, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5240391820209607. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8966101694915254, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.525681923959534. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9015254237288135, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5263431683196154. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9064406779661016, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.527866474568204. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9113559322033898, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.528021026552822. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.916271186440678, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5287675382632206. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9211864406779661, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5288292184642405. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9261016949152542, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5293964829031246. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9310169491525424, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5315213790370796. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9359322033898305, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5361733982978418. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9408474576271186, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5442663479200864. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9457627118644067, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5464831288255922. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9506779661016949, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.549872968749908. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.955593220338983, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5511323713583707. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9605084745762712, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5520575372306715. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9654237288135593, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5516600809508625. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9703389830508474, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.551597669747728. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9752542372881357, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5512250715582712. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9801694915254238, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5510387724635426. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9850847457627119, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5483881172263119. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.99, embed_dim_1=10, num_heads_1=2, embed_dim_2=20, num_heads_2=4, embed_dim_3=25, num_heads_3=5\n",
            "Validation accuracy: 1.5281159015029266. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5282782926161689. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7049152542372881, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5315886077758183. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7098305084745762, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5319914905958671. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7147457627118644, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5322313083396268. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7196610169491525, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.532697617310676. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7245762711864406, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5333728495404002. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7294915254237287, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5364456001112219. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7344067796610169, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5374955887246227. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7393220338983051, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5380747162827086. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7442372881355932, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5412347248638496. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7491525423728813, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.54307515805286. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7540677966101694, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5438792817642004. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7589830508474575, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5452572000503428. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7638983050847458, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5461347160051786. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7688135593220339, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5474982975818312. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.773728813559322, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.548724797772194. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7786440677966101, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.55070553552044. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7835593220338983, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.554911394183339. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7884745762711864, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5557763783828964. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7933898305084746, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5571509488296318. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7983050847457627, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5583736313885557. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8032203389830508, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5590915288568215. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8081355932203389, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5589507280660602. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8130508474576271, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5618987037820675. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8179661016949152, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5631780314000956. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8228813559322034, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5651511240684601. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8277966101694915, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.567139286239108. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8327118644067797, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5686157919853765. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8376271186440678, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5695117958708513. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8425423728813559, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5699597978135889. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.847457627118644, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5708622960383523. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8523728813559321, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5714417968666194. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8572881355932203, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.571254734022535. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8622033898305085, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5714713199016552. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8671186440677966, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.573670818467968. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8720338983050847, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5738562968915675. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8769491525423728, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5740303053823048. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.881864406779661, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5756114018333556. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8867796610169492, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5760780436843862. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8916949152542373, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.575498748552934. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8966101694915254, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5765747921171993. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9015254237288135, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.576940883247318. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9064406779661016, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5777177126806332. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9113559322033898, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5778933455943909. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.916271186440678, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.57915874201537. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9211864406779661, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.580099409238633. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9261016949152542, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5853021073885716. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9310169491525424, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5897554663964697. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9359322033898305, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.5958019593116712. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9408474576271186, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.6005836918882435. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9457627118644067, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.6038949020816635. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9506779661016949, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.6067620125914868. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.955593220338983, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.6097650670370096. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9605084745762712, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.6127781459492203. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9654237288135593, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.618462984206824. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9703389830508474, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.6195772371666561. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9752542372881357, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.6195533077223327. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9801694915254238, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.6155315171522808. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9850847457627119, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.606701737661219. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.99, embed_dim_1=20, num_heads_1=4, embed_dim_2=25, num_heads_2=5, embed_dim_3=50, num_heads_3=5\n",
            "Validation accuracy: 1.6032783865756879. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6061052705263381. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7049152542372881, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.609125086277145. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7098305084745762, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6096040712097381. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7147457627118644, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6102403996592864. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7196610169491525, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6109205256615775. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7245762711864406, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6123454970246929. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7294915254237287, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6138850159250366. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7344067796610169, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6138733171431743. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7393220338983051, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6169497776242738. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7442372881355932, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6177745198923152. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7491525423728813, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6193116036354103. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7540677966101694, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.620787184183156. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7589830508474575, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6241980122387827. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7638983050847458, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6245628377221588. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7688135593220339, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.625969789605791. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.773728813559322, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6260444945213743. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7786440677966101, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6264665464246209. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7835593220338983, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6265226025727355. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7884745762711864, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6264866912644322. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7933898305084746, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6263868366350802. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7983050847457627, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6272074658567255. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8032203389830508, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.628524183506069. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8081355932203389, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.629386489353347. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8130508474576271, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6309104288831135. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8179661016949152, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6326087379469787. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8228813559322034, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6343820213335711. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8277966101694915, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6355493361185962. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8327118644067797, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6364036248731981. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8376271186440678, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6357863477057388. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8425423728813559, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6362761805897277. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.847457627118644, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6378778260940152. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8523728813559321, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6387613127797738. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8572881355932203, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6406859886219953. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8622033898305085, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6437586425603647. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8671186440677966, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6456902811214147. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8720338983050847, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6470064403779565. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8769491525423728, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6480313914511666. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.881864406779661, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6485058468682219. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8867796610169492, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.652271424217518. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8916949152542373, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6525791638697722. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8966101694915254, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6528888705759774. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9015254237288135, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.653350480054359. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9064406779661016, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.654108024942135. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9113559322033898, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6551733094821648. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.916271186440678, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6550213523486301. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9211864406779661, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6545945034257232. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9261016949152542, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6548186181724733. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9310169491525424, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6552310263502537. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9359322033898305, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6547862852913662. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9408474576271186, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.654256343584954. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9457627118644067, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6528776756507981. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9506779661016949, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6510228796783548. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.955593220338983, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.65065511900738. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9605084745762712, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6504613699355228. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9654237288135593, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6474588304866524. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9703389830508474, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6435402517833557. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9752542372881357, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.636622008967599. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9801694915254238, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6250051900978997. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9850847457627119, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.5836424281014203. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.99, embed_dim_1=25, num_heads_1=5, embed_dim_2=50, num_heads_2=5, embed_dim_3=100, num_heads_3=5\n",
            "Validation accuracy: 1.6652611365456822. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.665755981906507. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7049152542372881, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6665197535617278. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7098305084745762, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6667299181484525. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7147457627118644, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6676273679585447. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7196610169491525, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.668557245815414. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7245762711864406, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6691016429823757. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7294915254237287, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6695140141163962. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7344067796610169, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.670548920971162. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7393220338983051, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6712641403673683. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7442372881355932, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6717051720600675. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7491525423728813, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6727358940098016. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7540677966101694, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.673178500212831. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7589830508474575, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6739882700430542. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7638983050847458, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6746839222169672. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7688135593220339, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6746298779643782. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.773728813559322, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6760554469668185. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7786440677966101, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.677523837919535. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7835593220338983, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6773769716185303. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7884745762711864, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6786451570230245. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7933898305084746, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6786130209698897. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7983050847457627, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.678134248211316. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8032203389830508, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6782836580424831. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8081355932203389, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.677662661060055. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8130508474576271, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6755428942344057. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8179661016949152, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6756175991499893. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8228813559322034, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6742927448839584. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8277966101694915, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6734978323243401. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8327118644067797, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6734978323243401. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8376271186440678, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6714561660922551. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8425423728813559, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6698663409730183. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.847457627118644, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6686739721335906. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8523728813559321, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.66734911786756. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8572881355932203, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6674256042994133. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8622033898305085, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6661007500333824. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8671186440677966, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.666548979526883. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8720338983050847, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.666548979526883. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8769491525423728, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6654601405362857. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.881864406779661, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.664092540359285. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8867796610169492, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6617528895101294. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8916949152542373, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6584499963514607. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8966101694915254, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6537721503138973. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9015254237288135, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6518978788055918. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9064406779661016, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6445573666742974. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9113559322033898, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6394169321220984. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.916271186440678, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6330948666308394. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9211864406779661, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6244274241732213. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9261016949152542, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6158664071222102. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9310169491525424, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.5995971967353526. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9359322033898305, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.5824694807841073. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9408474576271186, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.5645839481926926. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9457627118644067, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.5380187275098247. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9506779661016949, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.5031220661425753. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.955593220338983, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.468048757539855. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9605084745762712, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.4087242496859353. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9654237288135593, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.357388362003777. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9703389830508474, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.303762115436354. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9752542372881357, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.2354703111136218. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9801694915254238, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.1484825776872267. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9850847457627119, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.049991213901745. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.99, embed_dim_1=50, num_heads_1=5, embed_dim_2=100, num_heads_2=5, embed_dim_3=125, num_heads_3=5\n",
            "Validation accuracy: 1.6920119073974023. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6920119073974023. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7049152542372881, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6914044362623386. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7098305084745762, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6920536603803318. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7147457627118644, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6920189269314079. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7196610169491525, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6918732384897823. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7245762711864406, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6918732384897823. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7294915254237287, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6920992931098047. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7344067796610169, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6908991895205716. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7393220338983051, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6895081380688775. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7442372881355932, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6895595357130189. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7491525423728813, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6891060804384601. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7540677966101694, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6877630428297015. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7589830508474575, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6881472960944885. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7638983050847458, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6879201408933042. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7688135593220339, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6878722774895203. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.773728813559322, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6851625674894892. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7786440677966101, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6836782556405299. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7835593220338983, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.682162854353198. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7884745762711864, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6794454075339242. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7933898305084746, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6786265632724138. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.7983050847457627, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.677558421541947. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8032203389830508, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.674681557808701. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8081355932203389, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6710075961892126. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8130508474576271, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6679229709488674. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8179661016949152, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6632694118367428. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8228813559322034, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.661679586717506. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8277966101694915, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6582600720487495. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8327118644067797, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6542855092506574. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8376271186440678, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6490239451655637. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8425423728813559, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6421073863993991. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.847457627118644, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6357201981747336. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8523728813559321, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6297848510629158. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8572881355932203, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6240410842518354. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8622033898305085, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6142628402710446. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8671186440677966, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6080496586788455. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8720338983050847, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.6011604164954858. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8769491525423728, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.582849291543973. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.881864406779661, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.5709512807375328. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8867796610169492, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.5598048401793276. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8916949152542373, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.5468212683722267. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.8966101694915254, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.5315589472275524. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9015254237288135, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.5156077018645424. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9064406779661016, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.4960793499832488. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9113559322033898, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.481888946886022. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.916271186440678, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.4588099855717664. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9211864406779661, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.4323923915071135. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9261016949152542, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.4081620113943805. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9310169491525424, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.3797571359306815. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9359322033898305, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.339402074987385. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9408474576271186, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.3154487098575491. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9457627118644067, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.2888142182230575. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9506779661016949, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.2571179130640475. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.955593220338983, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.2243175626833456. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9605084745762712, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.1839322193568258. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9654237288135593, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.1422593542744077. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9703389830508474, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.0898802494286564. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9752542372881357, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 1.046950813116867. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9801694915254238, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 0.9998674386335533. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.9850847457627119, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Validation accuracy: 0.9597673711320304. Parameters: lr=0.001, momentum=0.9, num_epochs=10, batch_size=16, threshold=0.99, embed_dim_1=100, num_heads_1=5, embed_dim_2=125, num_heads_2=5, embed_dim_3=250, num_heads_3=10\n",
            "Best parameters: {'learning_rate': 0.001, 'momentum': 0.9, 'num_epochs': 10, 'batch_size': 16, 'threshold': 0.7344067796610169, 'embed_dim_1': 100, 'num_heads_1': 5, 'embed_dim_2': 125, 'num_heads_2': 5, 'embed_dim_3': 250, 'num_heads_3': 10}\n"
          ]
        }
      ],
      "source": [
        "lr_values = [0.001]\n",
        "momentum_values = [0.9]\n",
        "batch_size_values = [16]\n",
        "num_epochs_values = [10]\n",
        "threshold_values = np.linspace(0.7, 0.99, 60)\n",
        "model_parameters = [\n",
        "    (10,  2, 20,  4, 25,   5),\n",
        "    (20,  4, 25,  5, 50,   5),\n",
        "    (25,  5, 50,  5, 100,  5),\n",
        "    (50,  5, 100, 5, 125,  5),\n",
        "    (100, 5, 125, 5, 250, 10)\n",
        "]\n",
        "\n",
        "best_validation_accuracy = 0\n",
        "best_parameters = {}\n",
        "\n",
        "for lr in lr_values:\n",
        "    for momentum in momentum_values:\n",
        "        for num_epochs in num_epochs_values:\n",
        "            for batch_size in batch_size_values:\n",
        "                for embed_dim_1, num_heads_1, embed_dim_2, num_heads_2, embed_dim_3, num_heads_3 in model_parameters:\n",
        "                    model = AttentionNet(652, 368, embed_dim_1, num_heads_1, embed_dim_2, num_heads_2, embed_dim_3, num_heads_3)\n",
        "                    model.to(device)\n",
        "                    train(model, lr, momentum, num_epochs, batch_size)\n",
        "                    for threshold in threshold_values:\n",
        "                        validation_species_accuracy, validation_genera_accuracy = validate(model, threshold, batch_size)\n",
        "                        validation_accuracy = validation_species_accuracy + validation_genera_accuracy\n",
        "                        print((f\"Validation accuracy: {validation_accuracy}. \"\n",
        "                                f\"Parameters: lr={lr}, \"\n",
        "                                f\"momentum={momentum}, \"\n",
        "                                f\"num_epochs={num_epochs}, \"\n",
        "                                f\"batch_size={batch_size}, \"\n",
        "                                f\"threshold={threshold}, \"\n",
        "                                f\"embed_dim_1={embed_dim_1}, \"\n",
        "                                f\"num_heads_1={num_heads_1}, \"\n",
        "                                f\"embed_dim_2={embed_dim_2}, \"\n",
        "                                f\"num_heads_2={num_heads_2}, \"\n",
        "                                f\"embed_dim_3={embed_dim_3}, \"\n",
        "                                f\"num_heads_3={num_heads_3}\"))\n",
        "\n",
        "                        if validation_accuracy > best_validation_accuracy:\n",
        "                            best_validation_accuracy = validation_accuracy\n",
        "                            best_parameters = {\n",
        "                                'learning_rate': lr,\n",
        "                                'momentum': momentum,\n",
        "                                'num_epochs': num_epochs,\n",
        "                                'batch_size': batch_size,\n",
        "                                'threshold': threshold,\n",
        "                                'embed_dim_1': embed_dim_1,\n",
        "                                'num_heads_1': num_heads_1,\n",
        "                                'embed_dim_2': embed_dim_2,\n",
        "                                'num_heads_2': num_heads_2,\n",
        "                                'embed_dim_3': embed_dim_3,\n",
        "                                'num_heads_3': num_heads_3\n",
        "                            }\n",
        "\n",
        "print(\"Best parameters:\", best_parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final model training\n",
        "We select the best parameters found in the model selection section to train the final model on training and validation set.\n",
        "The model is then tested on the test set, which has $797$ seen species."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJgoWU0AusZr",
        "outputId": "69ce2de9-42cf-4a2a-ae95-7aedb040c2d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,   200] Species loss: 6.236; Genera loss: 5.076\n",
            "[1,   400] Species loss: 5.262; Genera loss: 3.700\n",
            "[1,   600] Species loss: 4.515; Genera loss: 2.961\n",
            "[1,   800] Species loss: 3.974; Genera loss: 2.436\n",
            "[1,  1000] Species loss: 3.545; Genera loss: 2.132\n",
            "[1,  1200] Species loss: 3.063; Genera loss: 1.778\n",
            "[2,   200] Species loss: 2.695; Genera loss: 1.544\n",
            "[2,   400] Species loss: 2.418; Genera loss: 1.384\n",
            "[2,   600] Species loss: 2.143; Genera loss: 1.239\n",
            "[2,   800] Species loss: 1.974; Genera loss: 1.145\n",
            "[2,  1000] Species loss: 1.842; Genera loss: 1.044\n",
            "[2,  1200] Species loss: 1.629; Genera loss: 0.939\n",
            "[3,   200] Species loss: 1.335; Genera loss: 0.752\n",
            "[3,   400] Species loss: 1.230; Genera loss: 0.720\n",
            "[3,   600] Species loss: 1.162; Genera loss: 0.691\n",
            "[3,   800] Species loss: 1.085; Genera loss: 0.629\n",
            "[3,  1000] Species loss: 0.910; Genera loss: 0.555\n",
            "[3,  1200] Species loss: 0.831; Genera loss: 0.529\n",
            "[4,   200] Species loss: 0.667; Genera loss: 0.411\n",
            "[4,   400] Species loss: 0.581; Genera loss: 0.378\n",
            "[4,   600] Species loss: 0.538; Genera loss: 0.344\n",
            "[4,   800] Species loss: 0.460; Genera loss: 0.315\n",
            "[4,  1000] Species loss: 0.436; Genera loss: 0.300\n",
            "[4,  1200] Species loss: 0.360; Genera loss: 0.254\n",
            "[5,   200] Species loss: 0.275; Genera loss: 0.209\n",
            "[5,   400] Species loss: 0.261; Genera loss: 0.209\n",
            "[5,   600] Species loss: 0.221; Genera loss: 0.169\n",
            "[5,   800] Species loss: 0.200; Genera loss: 0.163\n",
            "[5,  1000] Species loss: 0.180; Genera loss: 0.152\n",
            "[5,  1200] Species loss: 0.166; Genera loss: 0.145\n",
            "[6,   200] Species loss: 0.131; Genera loss: 0.109\n",
            "[6,   400] Species loss: 0.126; Genera loss: 0.105\n",
            "[6,   600] Species loss: 0.105; Genera loss: 0.099\n",
            "[6,   800] Species loss: 0.106; Genera loss: 0.103\n",
            "[6,  1000] Species loss: 0.099; Genera loss: 0.092\n",
            "[6,  1200] Species loss: 0.086; Genera loss: 0.095\n",
            "[7,   200] Species loss: 0.074; Genera loss: 0.068\n",
            "[7,   400] Species loss: 0.070; Genera loss: 0.073\n",
            "[7,   600] Species loss: 0.070; Genera loss: 0.064\n",
            "[7,   800] Species loss: 0.068; Genera loss: 0.067\n",
            "[7,  1000] Species loss: 0.060; Genera loss: 0.055\n",
            "[7,  1200] Species loss: 0.058; Genera loss: 0.056\n",
            "[8,   200] Species loss: 0.048; Genera loss: 0.050\n",
            "[8,   400] Species loss: 0.045; Genera loss: 0.042\n",
            "[8,   600] Species loss: 0.049; Genera loss: 0.046\n",
            "[8,   800] Species loss: 0.050; Genera loss: 0.047\n",
            "[8,  1000] Species loss: 0.039; Genera loss: 0.044\n",
            "[8,  1200] Species loss: 0.041; Genera loss: 0.040\n",
            "[9,   200] Species loss: 0.039; Genera loss: 0.047\n",
            "[9,   400] Species loss: 0.040; Genera loss: 0.039\n",
            "[9,   600] Species loss: 0.033; Genera loss: 0.033\n",
            "[9,   800] Species loss: 0.037; Genera loss: 0.038\n",
            "[9,  1000] Species loss: 0.031; Genera loss: 0.031\n",
            "[9,  1200] Species loss: 0.030; Genera loss: 0.032\n",
            "[10,   200] Species loss: 0.029; Genera loss: 0.026\n",
            "[10,   400] Species loss: 0.025; Genera loss: 0.029\n",
            "[10,   600] Species loss: 0.028; Genera loss: 0.031\n",
            "[10,   800] Species loss: 0.030; Genera loss: 0.030\n",
            "[10,  1000] Species loss: 0.023; Genera loss: 0.029\n",
            "[10,  1200] Species loss: 0.027; Genera loss: 0.028\n",
            "-------------------------------------------------------------------------------\n",
            "Final model described species accuracy:  0.9795431603890804\n",
            "Final model undescribed species accuracy:  0.7142266528247855\n",
            "-------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = AttentionNet(797, 368, best_parameters['embed_dim_1'], best_parameters['num_heads_1'], best_parameters['embed_dim_2'], best_parameters['num_heads_2'], best_parameters['embed_dim_3'], best_parameters['num_heads_3'])\n",
        "model.to(device)\n",
        "train(model, best_parameters['learning_rate'], best_parameters['momentum'], best_parameters['num_epochs'], best_parameters['batch_size'], train_val=True, print_losses=True)\n",
        "species_accuracy, genera_accuracy = test(model, best_parameters['threshold'], best_parameters['batch_size'])\n",
        "\n",
        "print(\"-------------------------------------------------------------------------------\")\n",
        "print(f\"Final model described species accuracy: \", species_accuracy)\n",
        "print(f\"Final model undescribed species accuracy: \", genera_accuracy)\n",
        "print(\"-------------------------------------------------------------------------------\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
